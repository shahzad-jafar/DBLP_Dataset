{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install pymongo\n",
    "#pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "import string\n",
    "import nltk\n",
    "import re\n",
    "#from tensorflow.keras import layers\n",
    "#from tensorflow import keras\n",
    "#import tensorflow as tf\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from ast import literal_eval\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = MongoClient(\"mongodb://localhost:27017/\")  #name of the connection string \n",
    "db = client[\"DBLP\"]             #name of the Database\n",
    "\n",
    "#collection_dblp = db[\"citation_data\"]    #Name of the item Name\n",
    "collection_dblp = db[\"new Data\"]\n",
    "collection_arix = db[\"Arix\"]  \n",
    "# Fetch all data\n",
    "cursor = collection_dblp.find()\n",
    "\n",
    "#cursor1 = collection_arix.find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(list(cursor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cursor = collection_dblp.find({}, {'year': 5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cursor1 = collection_dblp.find({'year': {'$gte': 1985}}, {'year': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data convert into the pandas dataframe\n",
    "#df1 = pd.DataFrame(list(cursor1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# article_counts = df1['year'].value_counts().sort_index()\n",
    "\n",
    "# # Plot the data\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# article_counts.plot(kind='bar', color='skyblue')\n",
    "# plt.title('Number of Articles Published Each Year')\n",
    "# plt.xlabel('Year')\n",
    "# plt.ylabel('Number of Articles')\n",
    "# plt.xticks(rotation=90)\n",
    "# plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rearrange the columns with proper way\n",
    "df=df[['_id','title','abstract','authors','n_citation','year','references','venue','id']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_id           object\n",
       "title         object\n",
       "abstract      object\n",
       "authors       object\n",
       "n_citation     int64\n",
       "year           int64\n",
       "references    object\n",
       "venue         object\n",
       "id            object\n",
       "dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#can be used to automatically convert object columns to a more specific data type\n",
    "df = df.infer_objects()\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000000, 9)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_null=df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_id                0\n",
       "title              0\n",
       "abstract      172467\n",
       "authors            2\n",
       "n_citation         0\n",
       "year               0\n",
       "references    124417\n",
       "venue         177755\n",
       "id                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df_null.isnull().sum()\n",
    "#.dropna(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing All Rows with NaN Values:\n",
    "df_null.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_id           0\n",
       "title         0\n",
       "abstract      0\n",
       "authors       0\n",
       "n_citation    0\n",
       "year          0\n",
       "references    0\n",
       "venue         0\n",
       "id            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_null.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(693622, 9)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_null.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_null.drop_duplicates(subset=['_id'], keep='first', inplace=True)\n",
    "df_null.reset_index(drop= True,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_id=df_null[['id','title','abstract','n_citation','references']]\n",
    "#df_referce=df_null[['id','references']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_id.to_csv('chuck.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_id=df_id.head(100000)\n",
    "# df_subset.to_csv('test.csv')# \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_id1=df_id.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>n_citation</th>\n",
       "      <th>references</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4ab3735c-80f1-472d-b953-fa0557fed28b</td>\n",
       "      <td>A new approach of 3D watermarking based on ima...</td>\n",
       "      <td>In this paper, a robust 3D triangular mesh wat...</td>\n",
       "      <td>50</td>\n",
       "      <td>['09cb2d7d-47d1-4a85-bfe5-faa8221e644b', '10aa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4ab39729-af77-46f7-a662-16984fb9c1db</td>\n",
       "      <td>Attractor neural networks with activity-depend...</td>\n",
       "      <td>We studied an autoassociative neural network w...</td>\n",
       "      <td>50</td>\n",
       "      <td>['4017c9d2-9845-4ad2-ad5b-ba65523727c5', 'b118...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4ab3a4cf-1d96-4ce5-ab6f-b3e19fc260de</td>\n",
       "      <td>A characterization of balanced episturmian seq...</td>\n",
       "      <td>It is well-known that Sturmian sequences are t...</td>\n",
       "      <td>50</td>\n",
       "      <td>['1c655ee2-067d-4bc4-b8cc-bc779e9a7f10', '2e4e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4ab3a98c-3620-47ec-b578-884ecf4a6206</td>\n",
       "      <td>Exploring the space of a human action</td>\n",
       "      <td>One of the fundamental challenges of recognizi...</td>\n",
       "      <td>221</td>\n",
       "      <td>['056116c1-9e7a-4f9b-a918-44eb199e67d6', '05ac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4ab3b585-82b4-4207-91dd-b6bce7e27c4e</td>\n",
       "      <td>Generalized upper bounds on the minimum distan...</td>\n",
       "      <td>This paper generalizes previous optimal upper ...</td>\n",
       "      <td>0</td>\n",
       "      <td>['01a765b8-0cb3-495c-996f-29c36756b435', '5dbc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4ab3e768-78c9-4497-8b8e-9e934cb5f2e4</td>\n",
       "      <td>Applying BCMP multi-class queueing networks fo...</td>\n",
       "      <td>Queueing networks with multiple classes of cus...</td>\n",
       "      <td>6</td>\n",
       "      <td>['1c26e228-57d2-4b2c-b0c9-8d5851c17fac', '7539...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4ab3f7cd-140b-4e29-99d4-f4e8006c4f65</td>\n",
       "      <td>A Push–Pull Class-C CMOS VCO</td>\n",
       "      <td>A CMOS oscillator employing differential trans...</td>\n",
       "      <td>50</td>\n",
       "      <td>['0a09db01-264a-4bdf-942c-d33cceb35d3c', '36c9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4ab404e2-6f4b-4fb4-b093-50775e765b13</td>\n",
       "      <td>On computability of pattern recognition problems</td>\n",
       "      <td>In statistical setting of the pattern recognit...</td>\n",
       "      <td>2</td>\n",
       "      <td>['505f493b-e09d-444d-9ee2-5e5db6a5b8ac']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4ab4244d-fb3e-49a3-b125-367df3d8e6ba</td>\n",
       "      <td>Manipulating biological and mechanical micro-o...</td>\n",
       "      <td>We first discuss some general aspects of micro...</td>\n",
       "      <td>50</td>\n",
       "      <td>['5ecd70e1-7ccc-4b2f-ac09-b91953cca5cd', '7fa7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4ab459ce-5f18-4cc0-9627-1dc557eb8b68</td>\n",
       "      <td>An abundance of invariant polynomials satisfyi...</td>\n",
       "      <td>In 1999, Iwan Duursma defined the zeta functio...</td>\n",
       "      <td>0</td>\n",
       "      <td>['02d38c7d-3baf-40e3-86d7-a8884ff503f4', '078e...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id   \n",
       "0  4ab3735c-80f1-472d-b953-fa0557fed28b  \\\n",
       "1  4ab39729-af77-46f7-a662-16984fb9c1db   \n",
       "2  4ab3a4cf-1d96-4ce5-ab6f-b3e19fc260de   \n",
       "3  4ab3a98c-3620-47ec-b578-884ecf4a6206   \n",
       "4  4ab3b585-82b4-4207-91dd-b6bce7e27c4e   \n",
       "5  4ab3e768-78c9-4497-8b8e-9e934cb5f2e4   \n",
       "6  4ab3f7cd-140b-4e29-99d4-f4e8006c4f65   \n",
       "7  4ab404e2-6f4b-4fb4-b093-50775e765b13   \n",
       "8  4ab4244d-fb3e-49a3-b125-367df3d8e6ba   \n",
       "9  4ab459ce-5f18-4cc0-9627-1dc557eb8b68   \n",
       "\n",
       "                                               title   \n",
       "0  A new approach of 3D watermarking based on ima...  \\\n",
       "1  Attractor neural networks with activity-depend...   \n",
       "2  A characterization of balanced episturmian seq...   \n",
       "3              Exploring the space of a human action   \n",
       "4  Generalized upper bounds on the minimum distan...   \n",
       "5  Applying BCMP multi-class queueing networks fo...   \n",
       "6                       A Push–Pull Class-C CMOS VCO   \n",
       "7   On computability of pattern recognition problems   \n",
       "8  Manipulating biological and mechanical micro-o...   \n",
       "9  An abundance of invariant polynomials satisfyi...   \n",
       "\n",
       "                                            abstract  n_citation   \n",
       "0  In this paper, a robust 3D triangular mesh wat...          50  \\\n",
       "1  We studied an autoassociative neural network w...          50   \n",
       "2  It is well-known that Sturmian sequences are t...          50   \n",
       "3  One of the fundamental challenges of recognizi...         221   \n",
       "4  This paper generalizes previous optimal upper ...           0   \n",
       "5  Queueing networks with multiple classes of cus...           6   \n",
       "6  A CMOS oscillator employing differential trans...          50   \n",
       "7  In statistical setting of the pattern recognit...           2   \n",
       "8  We first discuss some general aspects of micro...          50   \n",
       "9  In 1999, Iwan Duursma defined the zeta functio...           0   \n",
       "\n",
       "                                          references  \n",
       "0  ['09cb2d7d-47d1-4a85-bfe5-faa8221e644b', '10aa...  \n",
       "1  ['4017c9d2-9845-4ad2-ad5b-ba65523727c5', 'b118...  \n",
       "2  ['1c655ee2-067d-4bc4-b8cc-bc779e9a7f10', '2e4e...  \n",
       "3  ['056116c1-9e7a-4f9b-a918-44eb199e67d6', '05ac...  \n",
       "4  ['01a765b8-0cb3-495c-996f-29c36756b435', '5dbc...  \n",
       "5  ['1c26e228-57d2-4b2c-b0c9-8d5851c17fac', '7539...  \n",
       "6  ['0a09db01-264a-4bdf-942c-d33cceb35d3c', '36c9...  \n",
       "7           ['505f493b-e09d-444d-9ee2-5e5db6a5b8ac']  \n",
       "8  ['5ecd70e1-7ccc-4b2f-ac09-b91953cca5cd', '7fa7...  \n",
       "9  ['02d38c7d-3baf-40e3-86d7-a8884ff503f4', '078e...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_id1.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_referce = df_referce.assign(references=df_referce['references'].str.split(',')).explode('references')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "# # Define a function to safely get the length of iterable objects\n",
    "# def safe_len(value):\n",
    "#     if isinstance(value, (list, str)):\n",
    "#         return len(value)\n",
    "#     return 0  # or return a default value, or handle as needed\n",
    "\n",
    "# # Apply the function to calculate the count of references\n",
    "# df_id1['ref_count'] = df_id1['references'].apply(safe_len)\n",
    "\n",
    "# # Group by 'id', aggregate counts and collect titles\n",
    "# result = df_id1.groupby('id').agg({\n",
    "#     'ref_count': 'sum',  # Sum of references\n",
    "#     'title': lambda titles: ', '.join(pd.Series(titles).dropna())  # Concatenate titles\n",
    "# }).reset_index()\n",
    "\n",
    "# # Sort by the total reference count in descending order\n",
    "# result_sorted = result.sort_values(by='ref_count', ascending=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_id.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Download NLTK data\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('wordnet')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Steps for Natural Language Processing (NLP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Cleaning\n",
    "### I. Converting to lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>n_citation</th>\n",
       "      <th>references</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4ab3735c-80f1-472d-b953-fa0557fed28b</td>\n",
       "      <td>A new approach of 3D watermarking based on ima...</td>\n",
       "      <td>In this paper, a robust 3D triangular mesh wat...</td>\n",
       "      <td>50</td>\n",
       "      <td>['09cb2d7d-47d1-4a85-bfe5-faa8221e644b', '10aa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4ab39729-af77-46f7-a662-16984fb9c1db</td>\n",
       "      <td>Attractor neural networks with activity-depend...</td>\n",
       "      <td>We studied an autoassociative neural network w...</td>\n",
       "      <td>50</td>\n",
       "      <td>['4017c9d2-9845-4ad2-ad5b-ba65523727c5', 'b118...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4ab3a4cf-1d96-4ce5-ab6f-b3e19fc260de</td>\n",
       "      <td>A characterization of balanced episturmian seq...</td>\n",
       "      <td>It is well-known that Sturmian sequences are t...</td>\n",
       "      <td>50</td>\n",
       "      <td>['1c655ee2-067d-4bc4-b8cc-bc779e9a7f10', '2e4e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4ab3a98c-3620-47ec-b578-884ecf4a6206</td>\n",
       "      <td>Exploring the space of a human action</td>\n",
       "      <td>One of the fundamental challenges of recognizi...</td>\n",
       "      <td>221</td>\n",
       "      <td>['056116c1-9e7a-4f9b-a918-44eb199e67d6', '05ac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4ab3b585-82b4-4207-91dd-b6bce7e27c4e</td>\n",
       "      <td>Generalized upper bounds on the minimum distan...</td>\n",
       "      <td>This paper generalizes previous optimal upper ...</td>\n",
       "      <td>0</td>\n",
       "      <td>['01a765b8-0cb3-495c-996f-29c36756b435', '5dbc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>7116c792-5739-49a8-8150-3cf64124078a</td>\n",
       "      <td>Registration of 3D objects and surfaces</td>\n",
       "      <td>An approach to the problem of comparative anal...</td>\n",
       "      <td>91</td>\n",
       "      <td>['00e6f131-0fce-4b6f-8500-c1d701bb3cf8', '0e59...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>7117035a-0190-4404-bcec-3dc04404e005</td>\n",
       "      <td>Fetal electrocardiogram extraction by sequenti...</td>\n",
       "      <td>This work addresses the problem of fetal elect...</td>\n",
       "      <td>125</td>\n",
       "      <td>['1fb87d62-3355-4868-96f6-e63ae59e677a', '4234...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>7117606e-67f7-4c71-9c6c-2584da7e777c</td>\n",
       "      <td>The comment density of open source software code</td>\n",
       "      <td>The development processes of open source softw...</td>\n",
       "      <td>15</td>\n",
       "      <td>['08c0d910-e673-4da8-bec8-ea8f6b8184fd', '2361...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>711762b9-9799-4bc6-b890-e316094e070b</td>\n",
       "      <td>Supporting component and architectural re-usag...</td>\n",
       "      <td>We present an extended interface description l...</td>\n",
       "      <td>50</td>\n",
       "      <td>['1067759f-2494-49db-a9b2-a529d429a942']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>71177a1f-48d1-4419-b529-b156a8de3af7</td>\n",
       "      <td>Optimal SIR algorithm vs. fully adapted auxili...</td>\n",
       "      <td>Particle filters (PF) and auxiliary particle f...</td>\n",
       "      <td>50</td>\n",
       "      <td>['18b0b2e7-9bc8-4b97-83e9-dce169ff2fbb', '67ef...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         id   \n",
       "0      4ab3735c-80f1-472d-b953-fa0557fed28b  \\\n",
       "1      4ab39729-af77-46f7-a662-16984fb9c1db   \n",
       "2      4ab3a4cf-1d96-4ce5-ab6f-b3e19fc260de   \n",
       "3      4ab3a98c-3620-47ec-b578-884ecf4a6206   \n",
       "4      4ab3b585-82b4-4207-91dd-b6bce7e27c4e   \n",
       "...                                     ...   \n",
       "99995  7116c792-5739-49a8-8150-3cf64124078a   \n",
       "99996  7117035a-0190-4404-bcec-3dc04404e005   \n",
       "99997  7117606e-67f7-4c71-9c6c-2584da7e777c   \n",
       "99998  711762b9-9799-4bc6-b890-e316094e070b   \n",
       "99999  71177a1f-48d1-4419-b529-b156a8de3af7   \n",
       "\n",
       "                                                   title   \n",
       "0      A new approach of 3D watermarking based on ima...  \\\n",
       "1      Attractor neural networks with activity-depend...   \n",
       "2      A characterization of balanced episturmian seq...   \n",
       "3                  Exploring the space of a human action   \n",
       "4      Generalized upper bounds on the minimum distan...   \n",
       "...                                                  ...   \n",
       "99995            Registration of 3D objects and surfaces   \n",
       "99996  Fetal electrocardiogram extraction by sequenti...   \n",
       "99997   The comment density of open source software code   \n",
       "99998  Supporting component and architectural re-usag...   \n",
       "99999  Optimal SIR algorithm vs. fully adapted auxili...   \n",
       "\n",
       "                                                abstract  n_citation   \n",
       "0      In this paper, a robust 3D triangular mesh wat...          50  \\\n",
       "1      We studied an autoassociative neural network w...          50   \n",
       "2      It is well-known that Sturmian sequences are t...          50   \n",
       "3      One of the fundamental challenges of recognizi...         221   \n",
       "4      This paper generalizes previous optimal upper ...           0   \n",
       "...                                                  ...         ...   \n",
       "99995  An approach to the problem of comparative anal...          91   \n",
       "99996  This work addresses the problem of fetal elect...         125   \n",
       "99997  The development processes of open source softw...          15   \n",
       "99998  We present an extended interface description l...          50   \n",
       "99999  Particle filters (PF) and auxiliary particle f...          50   \n",
       "\n",
       "                                              references  \n",
       "0      ['09cb2d7d-47d1-4a85-bfe5-faa8221e644b', '10aa...  \n",
       "1      ['4017c9d2-9845-4ad2-ad5b-ba65523727c5', 'b118...  \n",
       "2      ['1c655ee2-067d-4bc4-b8cc-bc779e9a7f10', '2e4e...  \n",
       "3      ['056116c1-9e7a-4f9b-a918-44eb199e67d6', '05ac...  \n",
       "4      ['01a765b8-0cb3-495c-996f-29c36756b435', '5dbc...  \n",
       "...                                                  ...  \n",
       "99995  ['00e6f131-0fce-4b6f-8500-c1d701bb3cf8', '0e59...  \n",
       "99996  ['1fb87d62-3355-4868-96f6-e63ae59e677a', '4234...  \n",
       "99997  ['08c0d910-e673-4da8-bec8-ea8f6b8184fd', '2361...  \n",
       "99998           ['1067759f-2494-49db-a9b2-a529d429a942']  \n",
       "99999  ['18b0b2e7-9bc8-4b97-83e9-dce169ff2fbb', '67ef...  \n",
       "\n",
       "[100000 rows x 5 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_id = df_id.applymap(lambda x: x.lower() if isinstance(x, str) else x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II. Removing URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define a regex pattern to match URLs\n",
    "# url_pattern = re.compile(r'https?://\\S+')\n",
    "\n",
    "# # Define a function to remove URLs from text\n",
    "# def remove_urls(text):\n",
    "#     return url_pattern.sub('', text)\n",
    "\n",
    "# # Apply the function to the 'text' column and create a new column 'clean_text'\n",
    "# df_id['title'] = df_id['title'].apply(remove_urls)\n",
    "# df_id['abstract'] = df_id['abstract'].apply(remove_urls)\n",
    "\n",
    "url_pattern = re.compile(r'https?://\\S+')\n",
    "\n",
    "# Define a function to remove URLs from text\n",
    "def remove_urls(text):\n",
    "    if isinstance(text, list):\n",
    "        # Join list into a single string\n",
    "        text = ' '.join(text)\n",
    "    return url_pattern.sub('', text)\n",
    "\n",
    "# Apply the function to the 'title' and 'abstract' columns and create new columns 'clean_title' and 'clean_abstract'\n",
    "df_id['title'] = df_id['title'].apply(remove_urls)\n",
    "df_id['abstract'] = df_id['abstract'].apply(remove_urls)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### III. Removing remove non-word and non-whitespace characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_id['title'] = df_id['title'].replace(to_replace=r'[^\\w\\s\\b\\d+]', value='', regex=True)\n",
    "df_id['abstract'] = df_id['abstract'].replace(to_replace=r'[^\\w\\s\\b\\d+\\b]', value='', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def clean_reference(reference_list):\n",
    "#     # Convert list to string, then remove brackets from beginning, end, and middle\n",
    "#     if isinstance(reference_list, list):\n",
    "#         reference_str = ' '.join(reference_list)\n",
    "#     else:\n",
    "#         reference_str = reference_list\n",
    "#     return re.sub(r'[^\\w-]', '', reference_str)\n",
    "\n",
    "# # Apply the cleaning function to the 'reference' column\n",
    "# df_id['references'] = df_id['references'].apply(clean_reference)\n",
    "def clean_reference(reference_list):\n",
    "    # Check if input is a list\n",
    "    if isinstance(reference_list, list):\n",
    "        # Convert list to a single string\n",
    "        reference_str = ', '.join(reference_list)\n",
    "    else:\n",
    "        reference_str = reference_list\n",
    "\n",
    "    # Split the string by comma and clean each part\n",
    "    parts = reference_str.split(', ')\n",
    "    cleaned_parts = [re.sub(r'[^\\w-]', '', part) for part in parts]\n",
    "\n",
    "    # Recombine cleaned parts into a single string\n",
    "    cleaned_reference_str = ', '.join(cleaned_parts)\n",
    "    return cleaned_reference_str\n",
    "\n",
    "# Apply the cleaning function to the 'reference' column\n",
    "df_id['references'] = df_id['references'].apply(clean_reference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>n_citation</th>\n",
       "      <th>references</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4ab3735c-80f1-472d-b953-fa0557fed28b</td>\n",
       "      <td>a new approach of 3d watermarking based on ima...</td>\n",
       "      <td>in this paper a robust 3d triangular mesh wate...</td>\n",
       "      <td>50</td>\n",
       "      <td>09cb2d7d-47d1-4a85-bfe5-faa8221e644b, 10aa16da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4ab39729-af77-46f7-a662-16984fb9c1db</td>\n",
       "      <td>attractor neural networks with activitydepende...</td>\n",
       "      <td>we studied an autoassociative neural network w...</td>\n",
       "      <td>50</td>\n",
       "      <td>4017c9d2-9845-4ad2-ad5b-ba65523727c5, b1187381...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4ab3a4cf-1d96-4ce5-ab6f-b3e19fc260de</td>\n",
       "      <td>a characterization of balanced episturmian seq...</td>\n",
       "      <td>it is wellknown that sturmian sequences are th...</td>\n",
       "      <td>50</td>\n",
       "      <td>1c655ee2-067d-4bc4-b8cc-bc779e9a7f10, 2e4e57ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4ab3a98c-3620-47ec-b578-884ecf4a6206</td>\n",
       "      <td>exploring the space of a human action</td>\n",
       "      <td>one of the fundamental challenges of recognizi...</td>\n",
       "      <td>221</td>\n",
       "      <td>056116c1-9e7a-4f9b-a918-44eb199e67d6, 05ac52a1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4ab3b585-82b4-4207-91dd-b6bce7e27c4e</td>\n",
       "      <td>generalized upper bounds on the minimum distan...</td>\n",
       "      <td>this paper generalizes previous optimal upper ...</td>\n",
       "      <td>0</td>\n",
       "      <td>01a765b8-0cb3-495c-996f-29c36756b435, 5dbc8ccb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>7116c792-5739-49a8-8150-3cf64124078a</td>\n",
       "      <td>registration of 3d objects and surfaces</td>\n",
       "      <td>an approach to the problem of comparative anal...</td>\n",
       "      <td>91</td>\n",
       "      <td>00e6f131-0fce-4b6f-8500-c1d701bb3cf8, 0e592004...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>7117035a-0190-4404-bcec-3dc04404e005</td>\n",
       "      <td>fetal electrocardiogram extraction by sequenti...</td>\n",
       "      <td>this work addresses the problem of fetal elect...</td>\n",
       "      <td>125</td>\n",
       "      <td>1fb87d62-3355-4868-96f6-e63ae59e677a, 4234c39b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>7117606e-67f7-4c71-9c6c-2584da7e777c</td>\n",
       "      <td>the comment density of open source software code</td>\n",
       "      <td>the development processes of open source softw...</td>\n",
       "      <td>15</td>\n",
       "      <td>08c0d910-e673-4da8-bec8-ea8f6b8184fd, 23612fe0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>711762b9-9799-4bc6-b890-e316094e070b</td>\n",
       "      <td>supporting component and architectural reusage...</td>\n",
       "      <td>we present an extended interface description l...</td>\n",
       "      <td>50</td>\n",
       "      <td>1067759f-2494-49db-a9b2-a529d429a942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>71177a1f-48d1-4419-b529-b156a8de3af7</td>\n",
       "      <td>optimal sir algorithm vs fully adapted auxilia...</td>\n",
       "      <td>particle filters pf and auxiliary particle fil...</td>\n",
       "      <td>50</td>\n",
       "      <td>18b0b2e7-9bc8-4b97-83e9-dce169ff2fbb, 67efeb3a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         id   \n",
       "0      4ab3735c-80f1-472d-b953-fa0557fed28b  \\\n",
       "1      4ab39729-af77-46f7-a662-16984fb9c1db   \n",
       "2      4ab3a4cf-1d96-4ce5-ab6f-b3e19fc260de   \n",
       "3      4ab3a98c-3620-47ec-b578-884ecf4a6206   \n",
       "4      4ab3b585-82b4-4207-91dd-b6bce7e27c4e   \n",
       "...                                     ...   \n",
       "99995  7116c792-5739-49a8-8150-3cf64124078a   \n",
       "99996  7117035a-0190-4404-bcec-3dc04404e005   \n",
       "99997  7117606e-67f7-4c71-9c6c-2584da7e777c   \n",
       "99998  711762b9-9799-4bc6-b890-e316094e070b   \n",
       "99999  71177a1f-48d1-4419-b529-b156a8de3af7   \n",
       "\n",
       "                                                   title   \n",
       "0      a new approach of 3d watermarking based on ima...  \\\n",
       "1      attractor neural networks with activitydepende...   \n",
       "2      a characterization of balanced episturmian seq...   \n",
       "3                  exploring the space of a human action   \n",
       "4      generalized upper bounds on the minimum distan...   \n",
       "...                                                  ...   \n",
       "99995            registration of 3d objects and surfaces   \n",
       "99996  fetal electrocardiogram extraction by sequenti...   \n",
       "99997   the comment density of open source software code   \n",
       "99998  supporting component and architectural reusage...   \n",
       "99999  optimal sir algorithm vs fully adapted auxilia...   \n",
       "\n",
       "                                                abstract  n_citation   \n",
       "0      in this paper a robust 3d triangular mesh wate...          50  \\\n",
       "1      we studied an autoassociative neural network w...          50   \n",
       "2      it is wellknown that sturmian sequences are th...          50   \n",
       "3      one of the fundamental challenges of recognizi...         221   \n",
       "4      this paper generalizes previous optimal upper ...           0   \n",
       "...                                                  ...         ...   \n",
       "99995  an approach to the problem of comparative anal...          91   \n",
       "99996  this work addresses the problem of fetal elect...         125   \n",
       "99997  the development processes of open source softw...          15   \n",
       "99998  we present an extended interface description l...          50   \n",
       "99999  particle filters pf and auxiliary particle fil...          50   \n",
       "\n",
       "                                              references  \n",
       "0      09cb2d7d-47d1-4a85-bfe5-faa8221e644b, 10aa16da...  \n",
       "1      4017c9d2-9845-4ad2-ad5b-ba65523727c5, b1187381...  \n",
       "2      1c655ee2-067d-4bc4-b8cc-bc779e9a7f10, 2e4e57ca...  \n",
       "3      056116c1-9e7a-4f9b-a918-44eb199e67d6, 05ac52a1...  \n",
       "4      01a765b8-0cb3-495c-996f-29c36756b435, 5dbc8ccb...  \n",
       "...                                                  ...  \n",
       "99995  00e6f131-0fce-4b6f-8500-c1d701bb3cf8, 0e592004...  \n",
       "99996  1fb87d62-3355-4868-96f6-e63ae59e677a, 4234c39b...  \n",
       "99997  08c0d910-e673-4da8-bec8-ea8f6b8184fd, 23612fe0...  \n",
       "99998               1067759f-2494-49db-a9b2-a529d429a942  \n",
       "99999  18b0b2e7-9bc8-4b97-83e9-dce169ff2fbb, 67efeb3a...  \n",
       "\n",
       "[100000 rows x 5 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_referce = df_id1.assign(references=df_id1['references'].str.split(',')).explode('references')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>n_citation</th>\n",
       "      <th>references</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4ab3735c-80f1-472d-b953-fa0557fed28b</td>\n",
       "      <td>A new approach of 3D watermarking based on ima...</td>\n",
       "      <td>In this paper, a robust 3D triangular mesh wat...</td>\n",
       "      <td>50</td>\n",
       "      <td>['09cb2d7d-47d1-4a85-bfe5-faa8221e644b'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4ab3735c-80f1-472d-b953-fa0557fed28b</td>\n",
       "      <td>A new approach of 3D watermarking based on ima...</td>\n",
       "      <td>In this paper, a robust 3D triangular mesh wat...</td>\n",
       "      <td>50</td>\n",
       "      <td>'10aa16da-3cc8-4af6-9d66-48037e915d76'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4ab3735c-80f1-472d-b953-fa0557fed28b</td>\n",
       "      <td>A new approach of 3D watermarking based on ima...</td>\n",
       "      <td>In this paper, a robust 3D triangular mesh wat...</td>\n",
       "      <td>50</td>\n",
       "      <td>'35cb45c3-9408-4096-ab30-bc2e4de3fb5d'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4ab3735c-80f1-472d-b953-fa0557fed28b</td>\n",
       "      <td>A new approach of 3D watermarking based on ima...</td>\n",
       "      <td>In this paper, a robust 3D triangular mesh wat...</td>\n",
       "      <td>50</td>\n",
       "      <td>'661a342e-a911-4420-b67d-51c75d3b14e9'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4ab3735c-80f1-472d-b953-fa0557fed28b</td>\n",
       "      <td>A new approach of 3D watermarking based on ima...</td>\n",
       "      <td>In this paper, a robust 3D triangular mesh wat...</td>\n",
       "      <td>50</td>\n",
       "      <td>'779553f3-e4c1-456e-bc01-5eb9d9567541'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>7117606e-67f7-4c71-9c6c-2584da7e777c</td>\n",
       "      <td>The comment density of open source software code</td>\n",
       "      <td>The development processes of open source softw...</td>\n",
       "      <td>15</td>\n",
       "      <td>'65a9df5a-0d41-498a-a436-48213c74ae06'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>7117606e-67f7-4c71-9c6c-2584da7e777c</td>\n",
       "      <td>The comment density of open source software code</td>\n",
       "      <td>The development processes of open source softw...</td>\n",
       "      <td>15</td>\n",
       "      <td>'e0828ce7-b08c-4026-866f-916b22d8844c']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>711762b9-9799-4bc6-b890-e316094e070b</td>\n",
       "      <td>Supporting component and architectural re-usag...</td>\n",
       "      <td>We present an extended interface description l...</td>\n",
       "      <td>50</td>\n",
       "      <td>['1067759f-2494-49db-a9b2-a529d429a942']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>71177a1f-48d1-4419-b529-b156a8de3af7</td>\n",
       "      <td>Optimal SIR algorithm vs. fully adapted auxili...</td>\n",
       "      <td>Particle filters (PF) and auxiliary particle f...</td>\n",
       "      <td>50</td>\n",
       "      <td>['18b0b2e7-9bc8-4b97-83e9-dce169ff2fbb'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>71177a1f-48d1-4419-b529-b156a8de3af7</td>\n",
       "      <td>Optimal SIR algorithm vs. fully adapted auxili...</td>\n",
       "      <td>Particle filters (PF) and auxiliary particle f...</td>\n",
       "      <td>50</td>\n",
       "      <td>'67efeb3a-56bb-4bd8-bc0b-dca8f84fa3d3']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>914712 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         id   \n",
       "0      4ab3735c-80f1-472d-b953-fa0557fed28b  \\\n",
       "0      4ab3735c-80f1-472d-b953-fa0557fed28b   \n",
       "0      4ab3735c-80f1-472d-b953-fa0557fed28b   \n",
       "0      4ab3735c-80f1-472d-b953-fa0557fed28b   \n",
       "0      4ab3735c-80f1-472d-b953-fa0557fed28b   \n",
       "...                                     ...   \n",
       "99997  7117606e-67f7-4c71-9c6c-2584da7e777c   \n",
       "99997  7117606e-67f7-4c71-9c6c-2584da7e777c   \n",
       "99998  711762b9-9799-4bc6-b890-e316094e070b   \n",
       "99999  71177a1f-48d1-4419-b529-b156a8de3af7   \n",
       "99999  71177a1f-48d1-4419-b529-b156a8de3af7   \n",
       "\n",
       "                                                   title   \n",
       "0      A new approach of 3D watermarking based on ima...  \\\n",
       "0      A new approach of 3D watermarking based on ima...   \n",
       "0      A new approach of 3D watermarking based on ima...   \n",
       "0      A new approach of 3D watermarking based on ima...   \n",
       "0      A new approach of 3D watermarking based on ima...   \n",
       "...                                                  ...   \n",
       "99997   The comment density of open source software code   \n",
       "99997   The comment density of open source software code   \n",
       "99998  Supporting component and architectural re-usag...   \n",
       "99999  Optimal SIR algorithm vs. fully adapted auxili...   \n",
       "99999  Optimal SIR algorithm vs. fully adapted auxili...   \n",
       "\n",
       "                                                abstract  n_citation   \n",
       "0      In this paper, a robust 3D triangular mesh wat...          50  \\\n",
       "0      In this paper, a robust 3D triangular mesh wat...          50   \n",
       "0      In this paper, a robust 3D triangular mesh wat...          50   \n",
       "0      In this paper, a robust 3D triangular mesh wat...          50   \n",
       "0      In this paper, a robust 3D triangular mesh wat...          50   \n",
       "...                                                  ...         ...   \n",
       "99997  The development processes of open source softw...          15   \n",
       "99997  The development processes of open source softw...          15   \n",
       "99998  We present an extended interface description l...          50   \n",
       "99999  Particle filters (PF) and auxiliary particle f...          50   \n",
       "99999  Particle filters (PF) and auxiliary particle f...          50   \n",
       "\n",
       "                                     references  \n",
       "0       ['09cb2d7d-47d1-4a85-bfe5-faa8221e644b'  \n",
       "0        '10aa16da-3cc8-4af6-9d66-48037e915d76'  \n",
       "0        '35cb45c3-9408-4096-ab30-bc2e4de3fb5d'  \n",
       "0        '661a342e-a911-4420-b67d-51c75d3b14e9'  \n",
       "0        '779553f3-e4c1-456e-bc01-5eb9d9567541'  \n",
       "...                                         ...  \n",
       "99997    '65a9df5a-0d41-498a-a436-48213c74ae06'  \n",
       "99997   'e0828ce7-b08c-4026-866f-916b22d8844c']  \n",
       "99998  ['1067759f-2494-49db-a9b2-a529d429a942']  \n",
       "99999   ['18b0b2e7-9bc8-4b97-83e9-dce169ff2fbb'  \n",
       "99999   '67efeb3a-56bb-4bd8-bc0b-dca8f84fa3d3']  \n",
       "\n",
       "[914712 rows x 5 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_referce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>references</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4ab3735c-80f1-472d-b953-fa0557fed28b</td>\n",
       "      <td>['09cb2d7d-47d1-4a85-bfe5-faa8221e644b'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4ab3735c-80f1-472d-b953-fa0557fed28b</td>\n",
       "      <td>'10aa16da-3cc8-4af6-9d66-48037e915d76'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4ab3735c-80f1-472d-b953-fa0557fed28b</td>\n",
       "      <td>'35cb45c3-9408-4096-ab30-bc2e4de3fb5d'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4ab3735c-80f1-472d-b953-fa0557fed28b</td>\n",
       "      <td>'661a342e-a911-4420-b67d-51c75d3b14e9'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4ab3735c-80f1-472d-b953-fa0557fed28b</td>\n",
       "      <td>'779553f3-e4c1-456e-bc01-5eb9d9567541'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>7117606e-67f7-4c71-9c6c-2584da7e777c</td>\n",
       "      <td>'65a9df5a-0d41-498a-a436-48213c74ae06'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>7117606e-67f7-4c71-9c6c-2584da7e777c</td>\n",
       "      <td>'e0828ce7-b08c-4026-866f-916b22d8844c']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>711762b9-9799-4bc6-b890-e316094e070b</td>\n",
       "      <td>['1067759f-2494-49db-a9b2-a529d429a942']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>71177a1f-48d1-4419-b529-b156a8de3af7</td>\n",
       "      <td>['18b0b2e7-9bc8-4b97-83e9-dce169ff2fbb'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>71177a1f-48d1-4419-b529-b156a8de3af7</td>\n",
       "      <td>'67efeb3a-56bb-4bd8-bc0b-dca8f84fa3d3']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>914712 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         id   \n",
       "0      4ab3735c-80f1-472d-b953-fa0557fed28b  \\\n",
       "0      4ab3735c-80f1-472d-b953-fa0557fed28b   \n",
       "0      4ab3735c-80f1-472d-b953-fa0557fed28b   \n",
       "0      4ab3735c-80f1-472d-b953-fa0557fed28b   \n",
       "0      4ab3735c-80f1-472d-b953-fa0557fed28b   \n",
       "...                                     ...   \n",
       "99997  7117606e-67f7-4c71-9c6c-2584da7e777c   \n",
       "99997  7117606e-67f7-4c71-9c6c-2584da7e777c   \n",
       "99998  711762b9-9799-4bc6-b890-e316094e070b   \n",
       "99999  71177a1f-48d1-4419-b529-b156a8de3af7   \n",
       "99999  71177a1f-48d1-4419-b529-b156a8de3af7   \n",
       "\n",
       "                                     references  \n",
       "0       ['09cb2d7d-47d1-4a85-bfe5-faa8221e644b'  \n",
       "0        '10aa16da-3cc8-4af6-9d66-48037e915d76'  \n",
       "0        '35cb45c3-9408-4096-ab30-bc2e4de3fb5d'  \n",
       "0        '661a342e-a911-4420-b67d-51c75d3b14e9'  \n",
       "0        '779553f3-e4c1-456e-bc01-5eb9d9567541'  \n",
       "...                                         ...  \n",
       "99997    '65a9df5a-0d41-498a-a436-48213c74ae06'  \n",
       "99997   'e0828ce7-b08c-4026-866f-916b22d8844c']  \n",
       "99998  ['1067759f-2494-49db-a9b2-a529d429a942']  \n",
       "99999   ['18b0b2e7-9bc8-4b97-83e9-dce169ff2fbb'  \n",
       "99999   '67efeb3a-56bb-4bd8-bc0b-dca8f84fa3d3']  \n",
       "\n",
       "[914712 rows x 2 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_refere=df_referce[['id','references']]\n",
    "df_refere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_refere.to_csv('separte.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IV. Removing digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_id['title'] = df_id['title'].replace(to_replace=r'\\d', value='', regex=True)\n",
    "df_id['abstract'] = df_id['abstract'].replace(to_replace=r'\\d', value='', regex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Tokenization\n",
    "#### Tokenization is the process of breaking down large blocks of text such as paragraphs and sentences into smaller, more manageable units."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_id['title'] = df_id['title'].apply(word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_id['abstract'] = df_id['abstract'].apply(word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>n_citation</th>\n",
       "      <th>references</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4ab3735c-80f1-472d-b953-fa0557fed28b</td>\n",
       "      <td>[a, new, approach, of, d, watermarking, based,...</td>\n",
       "      <td>[in, this, paper, a, robust, d, triangular, me...</td>\n",
       "      <td>50</td>\n",
       "      <td>09cb2d7d-47d1-4a85-bfe5-faa8221e644b, 10aa16da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4ab39729-af77-46f7-a662-16984fb9c1db</td>\n",
       "      <td>[attractor, neural, networks, with, activityde...</td>\n",
       "      <td>[we, studied, an, autoassociative, neural, net...</td>\n",
       "      <td>50</td>\n",
       "      <td>4017c9d2-9845-4ad2-ad5b-ba65523727c5, b1187381...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4ab3a4cf-1d96-4ce5-ab6f-b3e19fc260de</td>\n",
       "      <td>[a, characterization, of, balanced, episturmia...</td>\n",
       "      <td>[it, is, wellknown, that, sturmian, sequences,...</td>\n",
       "      <td>50</td>\n",
       "      <td>1c655ee2-067d-4bc4-b8cc-bc779e9a7f10, 2e4e57ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4ab3a98c-3620-47ec-b578-884ecf4a6206</td>\n",
       "      <td>[exploring, the, space, of, a, human, action]</td>\n",
       "      <td>[one, of, the, fundamental, challenges, of, re...</td>\n",
       "      <td>221</td>\n",
       "      <td>056116c1-9e7a-4f9b-a918-44eb199e67d6, 05ac52a1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4ab3b585-82b4-4207-91dd-b6bce7e27c4e</td>\n",
       "      <td>[generalized, upper, bounds, on, the, minimum,...</td>\n",
       "      <td>[this, paper, generalizes, previous, optimal, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>01a765b8-0cb3-495c-996f-29c36756b435, 5dbc8ccb...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id   \n",
       "0  4ab3735c-80f1-472d-b953-fa0557fed28b  \\\n",
       "1  4ab39729-af77-46f7-a662-16984fb9c1db   \n",
       "2  4ab3a4cf-1d96-4ce5-ab6f-b3e19fc260de   \n",
       "3  4ab3a98c-3620-47ec-b578-884ecf4a6206   \n",
       "4  4ab3b585-82b4-4207-91dd-b6bce7e27c4e   \n",
       "\n",
       "                                               title   \n",
       "0  [a, new, approach, of, d, watermarking, based,...  \\\n",
       "1  [attractor, neural, networks, with, activityde...   \n",
       "2  [a, characterization, of, balanced, episturmia...   \n",
       "3      [exploring, the, space, of, a, human, action]   \n",
       "4  [generalized, upper, bounds, on, the, minimum,...   \n",
       "\n",
       "                                            abstract  n_citation   \n",
       "0  [in, this, paper, a, robust, d, triangular, me...          50  \\\n",
       "1  [we, studied, an, autoassociative, neural, net...          50   \n",
       "2  [it, is, wellknown, that, sturmian, sequences,...          50   \n",
       "3  [one, of, the, fundamental, challenges, of, re...         221   \n",
       "4  [this, paper, generalizes, previous, optimal, ...           0   \n",
       "\n",
       "                                          references  \n",
       "0  09cb2d7d-47d1-4a85-bfe5-faa8221e644b, 10aa16da...  \n",
       "1  4017c9d2-9845-4ad2-ad5b-ba65523727c5, b1187381...  \n",
       "2  1c655ee2-067d-4bc4-b8cc-bc779e9a7f10, 2e4e57ca...  \n",
       "3  056116c1-9e7a-4f9b-a918-44eb199e67d6, 05ac52a1...  \n",
       "4  01a765b8-0cb3-495c-996f-29c36756b435, 5dbc8ccb...  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_id.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Stopword Removal\n",
    "#### Stopwords refer to the most commonly occurring words in any natural language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "df_id['title'] = df_id['title'].apply(lambda x: [word for word in x if word not in stop_words])\n",
    "df_id['abstract'] = df_id['abstract'].apply(lambda x: [word for word in x if word not in stop_words])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Stemming/Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Porter Stemmer\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "# Define a function to perform stemming on the 'text' column\n",
    "def stem_words(words):\n",
    "    return [stemmer.stem(word) for word in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function to the 'text' column and create a new column 'stemmed_text'\n",
    "df_id['title'] = df_id['title'].apply(stem_words)\n",
    "df_id['abstract'] = df_id['abstract'].apply(stem_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_top=df_id.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #nltk.download('all')\n",
    "# #nltk.download('averaged_perceptron_tagger')\n",
    "# # initialize lemmatizer\n",
    "# lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# # define function to lemmatize tokens\n",
    "# def lemmatize_tokens(tokens):\n",
    "#     # convert POS tag to WordNet format\n",
    "#     def get_wordnet_pos(word):\n",
    "#         tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "#         tag_dict = {\"J\": wordnet.ADJ,\n",
    "#                     \"N\": wordnet.NOUN,\n",
    "#                     \"V\": wordnet.VERB,\n",
    "#                     \"R\": wordnet.ADV}\n",
    "#         return tag_dict.get(tag, wordnet.NOUN)\n",
    "    \n",
    "#     # lemmatize tokens\n",
    "#     lemmas = [lemmatizer.lemmatize(token, get_wordnet_pos(token)) for token in tokens]\n",
    "    \n",
    "#     # return lemmatized tokens as a list\n",
    "#     return lemmas\n",
    "\n",
    "#     df_id['lemmatized_title'] = df_id['title'].apply(lemmatize_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # apply lemmatization function to column of dataframe\n",
    "# df_id['lemmatized_title'] = df_id['title'].apply(lemmatize_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_id['lemmatized_abstract'] = df_id['abstract'].apply(lemmatize_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import base64\n",
    "\n",
    "# # Assuming df_id is your DataFrame containing the ObjectId values in the column '_id'\n",
    "# df_id1 = df_id['_id']\n",
    "\n",
    "# # Convert ObjectId values to strings\n",
    "# df_id1_str = df_id1.astype(str)\n",
    "\n",
    "# # Apply base64 encoding to each element of the Series\n",
    "# encoded_values = df_id1_str.apply(lambda x: base64.b64encode(x.encode()))\n",
    "\n",
    "# # Print the encoded values\n",
    "# print(\"Encoded values:\")\n",
    "# print(encoded_values)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import hashlib\n",
    "\n",
    "# id_str = \"4ab3735c-80f1-472d-b953-fa0557fed28b\"\n",
    "# hashed_value = hashlib.sha256(id_str.encode()).hexdigest()\n",
    "# # print(\"Hashed value:\", hashed_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>n_citation</th>\n",
       "      <th>references</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4ab3735c-80f1-472d-b953-fa0557fed28b</td>\n",
       "      <td>[new, approach, watermark, base, imag, segment]</td>\n",
       "      <td>[paper, robust, triangular, mesh, watermark, a...</td>\n",
       "      <td>50</td>\n",
       "      <td>09cb2d7d-47d1-4a85-bfe5-faa8221e644b, 10aa16da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4ab39729-af77-46f7-a662-16984fb9c1db</td>\n",
       "      <td>[attractor, neural, network, activitydepend, s...</td>\n",
       "      <td>[studi, autoassoci, neural, network, dynam, sy...</td>\n",
       "      <td>50</td>\n",
       "      <td>4017c9d2-9845-4ad2-ad5b-ba65523727c5, b1187381...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4ab3a4cf-1d96-4ce5-ab6f-b3e19fc260de</td>\n",
       "      <td>[character, balanc, episturmian, sequenc]</td>\n",
       "      <td>[wellknown, sturmian, sequenc, non, ultim, per...</td>\n",
       "      <td>50</td>\n",
       "      <td>1c655ee2-067d-4bc4-b8cc-bc779e9a7f10, 2e4e57ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4ab3a98c-3620-47ec-b578-884ecf4a6206</td>\n",
       "      <td>[explor, space, human, action]</td>\n",
       "      <td>[one, fundament, challeng, recogn, action, acc...</td>\n",
       "      <td>221</td>\n",
       "      <td>056116c1-9e7a-4f9b-a918-44eb199e67d6, 05ac52a1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4ab3b585-82b4-4207-91dd-b6bce7e27c4e</td>\n",
       "      <td>[gener, upper, bound, minimum, distanc, psk, b...</td>\n",
       "      <td>[paper, gener, previou, optim, upper, bound, m...</td>\n",
       "      <td>0</td>\n",
       "      <td>01a765b8-0cb3-495c-996f-29c36756b435, 5dbc8ccb...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id   \n",
       "0  4ab3735c-80f1-472d-b953-fa0557fed28b  \\\n",
       "1  4ab39729-af77-46f7-a662-16984fb9c1db   \n",
       "2  4ab3a4cf-1d96-4ce5-ab6f-b3e19fc260de   \n",
       "3  4ab3a98c-3620-47ec-b578-884ecf4a6206   \n",
       "4  4ab3b585-82b4-4207-91dd-b6bce7e27c4e   \n",
       "\n",
       "                                               title   \n",
       "0    [new, approach, watermark, base, imag, segment]  \\\n",
       "1  [attractor, neural, network, activitydepend, s...   \n",
       "2          [character, balanc, episturmian, sequenc]   \n",
       "3                     [explor, space, human, action]   \n",
       "4  [gener, upper, bound, minimum, distanc, psk, b...   \n",
       "\n",
       "                                            abstract  n_citation   \n",
       "0  [paper, robust, triangular, mesh, watermark, a...          50  \\\n",
       "1  [studi, autoassoci, neural, network, dynam, sy...          50   \n",
       "2  [wellknown, sturmian, sequenc, non, ultim, per...          50   \n",
       "3  [one, fundament, challeng, recogn, action, acc...         221   \n",
       "4  [paper, gener, previou, optim, upper, bound, m...           0   \n",
       "\n",
       "                                          references  \n",
       "0  09cb2d7d-47d1-4a85-bfe5-faa8221e644b, 10aa16da...  \n",
       "1  4017c9d2-9845-4ad2-ad5b-ba65523727c5, b1187381...  \n",
       "2  1c655ee2-067d-4bc4-b8cc-bc779e9a7f10, 2e4e57ca...  \n",
       "3  056116c1-9e7a-4f9b-a918-44eb199e67d6, 05ac52a1...  \n",
       "4  01a765b8-0cb3-495c-996f-29c36756b435, 5dbc8ccb...  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_id.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Loading and Preprocessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.spatial.distance import cosine\n",
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "\n",
    "# Ensure the 'title' and 'abstract' columns contain strings\n",
    "df_id['title'] = df_id['title'].astype(str)\n",
    "df_id['abstract'] = df_id['abstract'].apply(lambda x: ' '.join(x) if isinstance(x, list) else str(x))\n",
    "\n",
    "# Concatenate title and abstract\n",
    "df_id['combined_text'] = df_id['title'] + \" \" + df_id['abstract']\n",
    "\n",
    "# Create TF-IDF vectorizer\n",
    "vectorizer = TfidfVectorizer(max_features=768)  # Adjust the max_features based on your needs\n",
    "\n",
    "# Fit and transform the combined text column\n",
    "df_id['combined_embeddings'] = list(vectorizer.fit_transform(df_id['combined_text']).toarray())\n",
    "\n",
    "# Ensure IDs are strings\n",
    "df_id['id'] = df_id['id'].astype(str)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to Chroma and create a collection\n",
    "client = chromadb.Client(Settings())\n",
    "combined_collection = client.create_collection(\"combined_embeddings\")\n",
    "\n",
    "# Convert numpy arrays to lists\n",
    "combined_embeddings = [emb.tolist() for emb in df_id[\"combined_embeddings\"]]\n",
    "\n",
    "# Split data into smaller batches\n",
    "def split_into_batches(data, batch_size):\n",
    "    for i in range(0, len(data), batch_size):\n",
    "        yield data[i:i + batch_size]\n",
    "\n",
    "# Add embeddings to the collection in batches\n",
    "batch_size = 5461  # Set to the maximum allowed batch size\n",
    "ids_batches = list(split_into_batches(df_id[\"id\"].tolist(), batch_size))\n",
    "combined_embeddings_batches = list(split_into_batches(combined_embeddings, batch_size))\n",
    "combined_metadatas_batches = list(split_into_batches(df_id[[\"title\", \"abstract\"]].to_dict(orient=\"records\"), batch_size))\n",
    "\n",
    "for ids_batch, combined_embeddings_batch, combined_metadatas_batch in zip(ids_batches, combined_embeddings_batches, combined_metadatas_batches):\n",
    "    combined_collection.add(ids=ids_batch, embeddings=combined_embeddings_batch, metadatas=combined_metadatas_batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# from scipy.spatial.distance import cosine\n",
    "# import chromadb\n",
    "# from chromadb.config import Settings\n",
    "\n",
    "\n",
    "# # Ensure the 'title' and 'abstract' columns contain strings\n",
    "# df_id['title'] = df_id['title'].astype(str)\n",
    "# df_id['abstract'] = df_id['abstract'].apply(lambda x: ' '.join(x) if isinstance(x, list) else str(x))\n",
    "\n",
    "# # Example additional metadata for re-ranking\n",
    "# df_id['citation_count'] = df_id['n_citation']  # Use actual citation counts\n",
    "\n",
    "# # Create TF-IDF vectorizer\n",
    "# vectorizer = TfidfVectorizer(max_features=768)  # Adjust the max_features based on your needs\n",
    "\n",
    "# # Fit and transform the title and abstract columns\n",
    "# df_id['title_embeddings'] = list(vectorizer.fit_transform(df_id['title']).toarray())\n",
    "# df_id['abstract_embeddings'] = list(vectorizer.fit_transform(df_id['abstract']).toarray())\n",
    "\n",
    "# # Convert lists in 'abstract' to strings for metadata\n",
    "# df_id['abstract_str'] = df_id['abstract']\n",
    "\n",
    "# # Ensure IDs are strings\n",
    "# df_id['_id'] = df_id['_id'].astype(str)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Embedding Storage in ChromaDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Connect to Chroma and create collections\n",
    "# client = chromadb.Client(Settings())\n",
    "# title_collection = client.create_collection(\"title_embeddings\")\n",
    "# abstract_collection = client.create_collection(\"abstract_embeddings\")\n",
    "\n",
    "# # Convert numpy arrays to lists\n",
    "# title_embeddings = [emb.tolist() for emb in df_id[\"title_embeddings\"]]\n",
    "# abstract_embeddings = [emb.tolist() for emb in df_id[\"abstract_embeddings\"]]\n",
    "\n",
    "# # Split data into smaller batches\n",
    "# def split_into_batches(data, batch_size):\n",
    "#     for i in range(0, len(data), batch_size):\n",
    "#         yield data[i:i + batch_size]\n",
    "\n",
    "# # Add embeddings to collections in batches\n",
    "# batch_size = 5461  # Set to the maximum allowed batch size\n",
    "# ids_batches = list(split_into_batches(df_id[\"_id\"].tolist(), batch_size))\n",
    "# title_embeddings_batches = list(split_into_batches(title_embeddings, batch_size))\n",
    "# abstract_embeddings_batches = list(split_into_batches(abstract_embeddings, batch_size))\n",
    "# title_metadatas_batches = list(split_into_batches(df_id[[\"title\"]].to_dict(orient=\"records\"), batch_size))\n",
    "# abstract_metadatas_batches = list(split_into_batches(df_id[[\"abstract_str\"]].to_dict(orient=\"records\"), batch_size))\n",
    "\n",
    "# for ids_batch, title_embeddings_batch, title_metadatas_batch in zip(ids_batches, title_embeddings_batches, title_metadatas_batches):\n",
    "#     title_collection.add(ids=ids_batch, embeddings=title_embeddings_batch, metadatas=title_metadatas_batch)\n",
    "\n",
    "# for ids_batch, abstract_embeddings_batch, abstract_metadatas_batch in zip(ids_batches, abstract_embeddings_batches, abstract_metadatas_batches):\n",
    "#     abstract_collection.add(ids=ids_batch, embeddings=abstract_embeddings_batch, metadatas=abstract_metadatas_batch)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Similarity Computation and Re-ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute similarity\n",
    "def compute_similarity(embedding1, embedding2):\n",
    "    return 1 - cosine(embedding1, embedding2)\n",
    "\n",
    "# Function to find similar texts\n",
    "def find_similar_texts(user_input, embedding_column, top_n=30):\n",
    "    user_embedding = vectorizer.transform([user_input]).toarray().squeeze()\n",
    "    \n",
    "    similarities = []\n",
    "    for idx, row in df_id.iterrows():\n",
    "        sim = compute_similarity(user_embedding, row[embedding_column])\n",
    "        similarities.append((row['id'], sim))\n",
    "    \n",
    "    # Sort by similarity and get top N results\n",
    "    similarities.sort(key=lambda x: x[1], reverse=True)\n",
    "    return similarities[:top_n]\n",
    "\n",
    "# Function for re-ranking the results\n",
    "def re_rank_results(similar_texts):\n",
    "    # Combine similarity score with citation count for re-ranking\n",
    "    re_ranked = []\n",
    "    for id, similarity in similar_texts:\n",
    "        citation_count = df_id[df_id[\"id\"] == id][\"citation_count\"].values[0]\n",
    "        # Example: Weighted combination of similarity and citation count\n",
    "        re_ranked_score = 0.8 * similarity + 0.2 * (citation_count / 100)  # Normalize citation_count to 0-1 range\n",
    "        re_ranked.append((id, re_ranked_score))\n",
    "    \n",
    "    # Sort by re-ranked score\n",
    "    re_ranked.sort(key=lambda x: x[1], reverse=True)\n",
    "    return re_ranked\n",
    "\n",
    "# Updated function to find similar texts and re-rank them\n",
    "def find_and_rerank_similar_texts(user_input, embedding_column, top_n=30):\n",
    "    similar_texts = find_similar_texts(user_input, embedding_column, top_n)\n",
    "    re_ranked_texts = re_rank_results(similar_texts)\n",
    "    return re_ranked_texts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# . Recommendation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics.pairwise import cosine_similarity\n",
    "# import numpy as np\n",
    "\n",
    "# # Function to compute similarity\n",
    "# def compute_similarity(embedding1, embedding2):\n",
    "#     return cosine_similarity([embedding1], [embedding2])[0][0]\n",
    "\n",
    "# # Function to find and rerank similar texts\n",
    "# def find_and_rerank_similar_texts(user_query, top_n=5):\n",
    "#     user_title_embedding = vectorizer.transform([user_query]).toarray().squeeze()\n",
    "#     user_abstract_embedding = vectorizer.transform([user_query]).toarray().squeeze()\n",
    "    \n",
    "#     similarities = []\n",
    "#     for idx, row in df_id.iterrows():\n",
    "#         title_sim = compute_similarity(user_title_embedding, row['title_embeddings'])\n",
    "#         abstract_sim = compute_similarity(user_abstract_embedding, row['abstract_embeddings'])\n",
    "#         combined_sim = 0.5 * title_sim + 0.5 * abstract_sim  # Equal weighting of title and abstract similarity\n",
    "#         similarities.append((row['_id'], row['title'], combined_sim))\n",
    "    \n",
    "#     # Sort by combined similarity and get top N results\n",
    "#     similarities.sort(key=lambda x: x[2], reverse=True)\n",
    "#     return similarities[:top_n]\n",
    "\n",
    "# # Function to recommend papers based on user input\n",
    "# def recommend_articles(user_query, top_n=5):\n",
    "#     # Find and rerank similar texts\n",
    "#     similar_texts = find_and_rerank_similar_texts(user_query, top_n)\n",
    "    \n",
    "#     recommended_articles = []\n",
    "#     for _id, title, score in similar_texts:\n",
    "#         recommended_articles.append((_id, title, score))\n",
    "    \n",
    "#     return recommended_articles\n",
    "\n",
    "# # Example usage\n",
    "# user_query = \"NLP for text analysis\"\n",
    "# recommended_articles = recommend_articles(user_query, top_n=5)\n",
    "\n",
    "# # Display the recommended articles\n",
    "# print(\"Recommended Articles:\")\n",
    "# for _id, title, score in recommended_articles:\n",
    "#     print(f\"ID: {_id}, Title: {title}, Similarity Score: {score}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New Codee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# from sklearn.metrics.pairwise import cosine_similarity\n",
    "# import numpy as np\n",
    "\n",
    "\n",
    "# # Function to compute similarity\n",
    "# def compute_similarity(embedding1, embedding2):\n",
    "#     return cosine_similarity([embedding1], [embedding2])[0][0]\n",
    "\n",
    "# # Function to compute keyword match score\n",
    "# def compute_keyword_match_score(user_keywords, title):\n",
    "#     title_words = set(title.lower().split())\n",
    "#     matched_keywords = user_keywords.intersection(title_words)\n",
    "#     return len(matched_keywords) / len(user_keywords) if user_keywords else 0\n",
    "\n",
    "# # Function to find and rerank similar texts\n",
    "# def find_and_rerank_similar_texts(user_query, top_n=5):\n",
    "#     user_query_embedding = vectorizer.transform([user_query]).toarray().squeeze()\n",
    "#     user_keywords = set(user_query.lower().split())\n",
    "    \n",
    "#     similarities = []\n",
    "#     for idx, row in df_id.iterrows():\n",
    "#         title_embedding = row['title_embeddings']\n",
    "#         abstract_embedding = row['abstract_embeddings']\n",
    "        \n",
    "#         title_sim = compute_similarity(user_query_embedding, title_embedding)\n",
    "#         abstract_sim = compute_similarity(user_query_embedding, abstract_embedding)\n",
    "#         keyword_match_score = compute_keyword_match_score(user_keywords, row['title'])\n",
    "        \n",
    "#         # Combined similarity with weights (adjust weights as needed)\n",
    "#         combined_sim = 0.4 * title_sim + 0.4 * abstract_sim + 0.2 * keyword_match_score\n",
    "        \n",
    "#         similarities.append((row['_id'], row['title'], combined_sim))\n",
    "    \n",
    "#     # Sort by combined similarity in descending order\n",
    "#     similarities.sort(key=lambda x: x[2], reverse=True)\n",
    "#     return similarities[:top_n]\n",
    "\n",
    "# # Function to recommend papers based on user input\n",
    "# def recommend_articles(user_query, top_n=5):\n",
    "#     # Find and rerank similar texts\n",
    "#     similar_texts = find_and_rerank_similar_texts(user_query, top_n)\n",
    "    \n",
    "#     recommended_articles = []\n",
    "#     for _id, title, score in similar_texts:\n",
    "#         recommended_articles.append((_id, title, score))\n",
    "    \n",
    "#     return recommended_articles\n",
    "\n",
    "# # Example usage\n",
    "# user_query = \"NLP for text analysis\"\n",
    "# recommended_articles = recommend_articles(user_query, top_n=5)\n",
    "\n",
    "# print(f\"Recommended Articles for '{user_query}':\")\n",
    "# for rank, (_id, title, score) in enumerate(recommended_articles, 1):\n",
    "#     print(f\"Rank {rank}: ID: {_id}, Title: {title}, Similarity Score: {score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended Articles for ' A new approach of 3D watermarking based on image segmentation':\n",
      "Rank 1: ID: 67a59884-926e-4d8f-b638-c5140b91dcf2, Title: ['paraphras', 'identif', 'lexicosyntact', 'graph', 'subsumpt'], Similarity Score: 0.5292\n",
      "Rank 2: ID: 505ea144-8353-456e-8adf-f0818f3bef0c, Title: ['teach', 'objectsfirst', 'introductori', 'comput', 'scienc'], Similarity Score: 0.4904\n",
      "Rank 3: ID: 536eddb5-b1ac-45dc-9dc7-2734970c84d2, Title: ['differ', 'quantis', 'nois', 'shape', 'method', 'predict', 'audio', 'code'], Similarity Score: 0.4603\n",
      "Rank 4: ID: 5ceab604-7649-4484-ac79-05bff7111aaf, Title: ['componentbas', 'approach', 'improv', 'modular', 'oscar'], Similarity Score: 0.4534\n",
      "Rank 5: ID: 6926c0c1-ef07-40ab-9992-ca2346b890c0, Title: ['branchandcut', 'approach', 'gener', 'multipleproduct', 'assemblysystem', 'design', 'problem'], Similarity Score: 0.4507\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Function to find and rerank similar texts using combined embeddings\n",
    "def find_and_rerank_similar_texts(user_query, top_n=5):\n",
    "    user_embedding = vectorizer.transform([user_query]).toarray().squeeze()\n",
    "    \n",
    "    similarities = []\n",
    "    for idx, row in df_id.iterrows():\n",
    "        combined_embedding = row['combined_embeddings']\n",
    "        \n",
    "        # Compute cosine similarity between user embedding and combined embedding\n",
    "        combined_sim = cosine_similarity([user_embedding], [combined_embedding])[0][0]\n",
    "        \n",
    "        similarities.append((row['id'], row['title'], combined_sim))\n",
    "    \n",
    "    # Sort by combined similarity in descending order\n",
    "    similarities.sort(key=lambda x: x[2], reverse=True)\n",
    "    return similarities[:top_n]\n",
    "\n",
    "# Function to recommend papers based on user input using combined embeddings\n",
    "def recommend_articles(user_query, top_n=5):\n",
    "    # Find and rerank similar texts using combined embeddings\n",
    "    similar_texts = find_and_rerank_similar_texts(user_query, top_n)\n",
    "    \n",
    "    recommended_articles = []\n",
    "    for id, title, score in similar_texts:\n",
    "        recommended_articles.append((id, title, score))\n",
    "        \n",
    "    \n",
    "    return recommended_articles\n",
    "\n",
    "# Example usage\n",
    "user_queries = [\n",
    "    \" A new approach of 3D watermarking based on image segmentation\"\n",
    "]\n",
    "\n",
    "for user_query in user_queries:\n",
    "    print(f\"Recommended Articles for '{user_query}':\")\n",
    "    recommended_articles = recommend_articles(user_query, top_n=5)\n",
    "\n",
    "    for rank, (id, title, score) in enumerate(recommended_articles, 1):\n",
    "        print(f\"Rank {rank}: ID: {id}, Title: {title}, Similarity Score: {score:.4f}\")\n",
    "    print()  # Print empty line for separation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User Input Exact Title: 'Bibliography on cyclostationarity':\n",
      "ID: 6d4c5b32-8e13-4022-b67f-1ace7ffc91d0, Title: Bibliography on cyclostationarity\n",
      "Rank 1: ID: 4ab3735c-80f1-472d-b953-fa0557fed28b, Title: ['new', 'approach', 'watermark', 'base', 'imag', 'segment'], Similarity Score: 0.0000\n",
      "Rank 2: ID: 4ab39729-af77-46f7-a662-16984fb9c1db, Title: ['attractor', 'neural', 'network', 'activitydepend', 'synaps', 'role', 'synapt', 'facilit'], Similarity Score: 0.0000\n",
      "Rank 3: ID: 4ab3a4cf-1d96-4ce5-ab6f-b3e19fc260de, Title: ['character', 'balanc', 'episturmian', 'sequenc'], Similarity Score: 0.0000\n",
      "Rank 4: ID: 4ab3a98c-3620-47ec-b578-884ecf4a6206, Title: ['explor', 'space', 'human', 'action'], Similarity Score: 0.0000\n",
      "Rank 5: ID: 4ab3b585-82b4-4207-91dd-b6bce7e27c4e, Title: ['gener', 'upper', 'bound', 'minimum', 'distanc', 'psk', 'block', 'code'], Similarity Score: 0.0000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Function to find the ID and title based on an exact title match\n",
    "def find_exact_title_match(title_query, df_id1):\n",
    "    for idx, row in df_id1.iterrows():\n",
    "        if row['title'].strip().lower() == title_query.strip().lower():\n",
    "            return row['id'], row['title']\n",
    "    return None, None  # Return None if no exact match is found\n",
    "\n",
    "# Function to find and rerank similar texts using combined embeddings\n",
    "def find_and_rerank_similar_texts(user_query, top_n=5):\n",
    "    user_embedding = vectorizer.transform([user_query]).toarray().squeeze()\n",
    "    \n",
    "    similarities = []\n",
    "    for idx, row in df_id.iterrows():\n",
    "        combined_embedding = row['combined_embeddings']\n",
    "        \n",
    "        # Compute cosine similarity between user embedding and combined embedding\n",
    "        combined_sim = cosine_similarity([user_embedding], [combined_embedding])[0][0]\n",
    "        \n",
    "        similarities.append((row['id'], row['title'], combined_sim))\n",
    "    \n",
    "    # Sort by combined similarity in descending order\n",
    "    similarities.sort(key=lambda x: x[2], reverse=True)\n",
    "    return similarities[:top_n]\n",
    "\n",
    "# Function to recommend papers based on user input using combined embeddings\n",
    "def recommend_articles(user_query, top_n=5):\n",
    "    # Find and rerank similar texts using combined embeddings\n",
    "    similar_texts = find_and_rerank_similar_texts(user_query, top_n)\n",
    "    \n",
    "    recommended_articles = []\n",
    "    for id, title, score in similar_texts:\n",
    "        recommended_articles.append((id, title, score))\n",
    "    \n",
    "    return recommended_articles\n",
    "\n",
    "\n",
    "# Function to evaluate recommendations\n",
    "\n",
    "\n",
    "# Example usage\n",
    "user_queries = [\n",
    "    \"Bibliography on cyclostationarity\"\n",
    "]\n",
    "\n",
    "for user_query in user_queries:\n",
    "    print(f\"User Input Exact Title: '{user_query}':\")\n",
    "    \n",
    "    # Check for exact title match in df_id1\n",
    "    exact_match_id, exact_match_title = find_exact_title_match(user_query, df_id1)\n",
    "    \n",
    "    if exact_match_id is not None:\n",
    "        print(f\"ID: {exact_match_id}, Title: {exact_match_title}\")\n",
    "        # stored_variable = (exact_match_id, exact_match_title)  # Store in variable\n",
    "        # print(f\"Stored Variable: {stored_variable}\")\n",
    "    else:\n",
    "        print(f\"No exact title match found in df_id1 for '{user_query}'\")\n",
    "    \n",
    "    # Proceed with recommendation if no exact match found\n",
    "    recommended_articles = recommend_articles(user_query, top_n=5)\n",
    "    for rank, (id, title, score) in enumerate(recommended_articles, 1):\n",
    "        print(f\"Rank {rank}: ID: {id}, Title: {title}, Similarity Score: {score:.4f}\")\n",
    "\n",
    "    # if exact_match_id is not None:\n",
    "    #     accuracy = evaluate_accuracy(exact_match_id, recommended_articles)\n",
    "    #     print(f\"Accuracy: {accuracy:.4f}\\n\")  # Print empty line for separation\n",
    "    # else:\n",
    "    #     print(f\"No exact title match found for '{user_query}' in df_id\\n\")\n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This Part can be used for Jaccard_Score Pipline 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User Input Exact Title: 'Bibliography on cyclostationarity':\n",
      "ID: 6d4c5b32-8e13-4022-b67f-1ace7ffc91d0, Title: Bibliography on cyclostationarity\n",
      "Rank 1: ID: 5abb4a53-a24d-48d4-84ed-8f90633a30ba, Title: ['enterpriseori', 'iot', 'name', 'servic', 'agricultur', 'product', 'suppli', 'chain', 'manag'], Jaccard Similarity Score: 0.0222\n",
      "Rank 2: ID: 69bcdef0-f057-43d4-8808-15e4e94f5038, Title: ['rainbow', 'turán', 'problem'], Jaccard Similarity Score: 0.0204\n",
      "Rank 3: ID: 5a49ccd4-417f-4585-9d69-7bceb3e13f17, Title: ['predict', 'genet', 'drift', 'game'], Jaccard Similarity Score: 0.0182\n",
      "Rank 4: ID: 6b7e733d-d80a-43c3-a722-caeee33c0374, Title: ['prototyp', 'multiroot', 'on'], Jaccard Similarity Score: 0.0169\n",
      "Rank 5: ID: 5d17295b-c527-47ef-b8aa-b481ab1c946d, Title: ['implement', 'secur', 'ppon'], Jaccard Similarity Score: 0.0125\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import jaccard_score\n",
    "import numpy as np\n",
    "\n",
    "# Function to find the ID and title based on an exact title match\n",
    "def find_exact_title_match(title_query, df_id1):\n",
    "    for idx, row in df_id1.iterrows():\n",
    "        if row['title'].strip().lower() == title_query.strip().lower():\n",
    "            return row['id'], row['title']\n",
    "    return None, None  # Return None if no exact match is found\n",
    "\n",
    "# Function to compute Jaccard similarity\n",
    "def jaccard_similarity(query, document):\n",
    "    query_set = set(query.split())\n",
    "    document_set = set(document.split())\n",
    "    intersection = query_set.intersection(document_set)\n",
    "    union = query_set.union(document_set)\n",
    "    if not union:  # Avoid division by zero\n",
    "        return 0.0\n",
    "    return len(intersection) / len(union)\n",
    "\n",
    "# Function to find and rerank similar texts using Jaccard similarity\n",
    "def find_and_rerank_similar_texts(user_query, df_id, top_n=5):\n",
    "    similarities = []\n",
    "    for idx, row in df_id.iterrows():\n",
    "        document = row['title'] + \" \" + row['abstract']  # Combine title and abstract\n",
    "        sim_score = jaccard_similarity(user_query, document)\n",
    "        similarities.append((row['id'], row['title'], sim_score))\n",
    "    \n",
    "    # Sort by Jaccard similarity in descending order\n",
    "    similarities.sort(key=lambda x: x[2], reverse=True)\n",
    "    return similarities[:top_n]\n",
    "\n",
    "# Function to recommend papers based on user input using Jaccard similarity\n",
    "def recommend_articles(user_query, df_id, top_n=5):\n",
    "    # Find and rerank similar texts using Jaccard similarity\n",
    "    similar_texts = find_and_rerank_similar_texts(user_query, df_id, top_n)\n",
    "    \n",
    "    recommended_articles = []\n",
    "    for id, title, score in similar_texts:\n",
    "        recommended_articles.append((id, title, score))\n",
    "    \n",
    "    return recommended_articles\n",
    "\n",
    "# Example usage\n",
    "user_queries = [\n",
    "    \"Bibliography on cyclostationarity\"\n",
    "]\n",
    "\n",
    "for user_query in user_queries:\n",
    "    print(f\"User Input Exact Title: '{user_query}':\")\n",
    "    \n",
    "    # Check for exact title match in df_id1\n",
    "    exact_match_id, exact_match_title = find_exact_title_match(user_query, df_id1)\n",
    "    \n",
    "    if exact_match_id is not None:\n",
    "        print(f\"ID: {exact_match_id}, Title: {exact_match_title}\")\n",
    "        # stored_variable = (exact_match_id, exact_match_title)  # Store in variable\n",
    "        # print(f\"Stored Variable: {stored_variable}\")\n",
    "    else:\n",
    "        print(f\"No exact title match found in df_id1 for '{user_query}'\")\n",
    "    \n",
    "    # Proceed with recommendation if no exact match found\n",
    "    recommended_articles = recommend_articles(user_query, df_id, top_n=5)\n",
    "    for rank, (id, title, score) in enumerate(recommended_articles, 1):\n",
    "        print(f\"Rank {rank}: ID: {id}, Title: {title}, Jaccard Similarity Score: {score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline 3: WordNet using the Cosine Smilirty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Shahzad\n",
      "[nltk_data]     Ahmad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to C:\\Users\\Shahzad\n",
      "[nltk_data]     Ahmad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to C:\\Users\\Shahzad\n",
      "[nltk_data]     Ahmad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to C:\\Users\\Shahzad\n",
      "[nltk_data]     Ahmad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import numpy as np\n",
    "\n",
    "# Download NLTK data\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import wordnet as wn\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Assuming nltk data is already downloaded in your environment\n",
    "\n",
    "# Function to find the ID and title based on an exact title match\n",
    "def find_exact_title_match(title_query, df_id1):\n",
    "    for idx, row in df_id1.iterrows():\n",
    "        if row['title'].strip().lower() == title_query.strip().lower():\n",
    "            return row['id'], row['title']\n",
    "    return None, None  # Return None if no exact match is found\n",
    "\n",
    "# Function to compute WordNet similarity between two words\n",
    "def wordnet_similarity(word1, word2):\n",
    "    synsets1 = wn.synsets(word1)\n",
    "    synsets2 = wn.synsets(word2)\n",
    "    if not synsets1 or not synsets2:  # If either word has no synsets\n",
    "        return 0\n",
    "    max_sim = max((syn1.path_similarity(syn2) or 0) for syn1 in synsets1 for syn2 in synsets2)\n",
    "    return max_sim\n",
    "\n",
    "# Function to compute similarity between two texts using WordNet\n",
    "def text_similarity(text1, text2):\n",
    "    words1 = text1.split()\n",
    "    words2 = text2.split()\n",
    "    if not words1 or not words2:  # If either text has no valid words\n",
    "        return 0\n",
    "    total_sim = 0\n",
    "    for word1 in words1:\n",
    "        word_sim = max(wordnet_similarity(word1, word2) for word2 in words2)\n",
    "        total_sim += word_sim\n",
    "    return total_sim / max(len(words1), len(words2))  # Normalize by the number of words\n",
    "\n",
    "# Function to compute cosine similarity\n",
    "def compute_cosine_similarity(user_query, df_id, vectorizer):\n",
    "    user_embedding = vectorizer.transform([user_query]).toarray().squeeze()\n",
    "    cosine_similarities = []\n",
    "    for idx, row in df_id.iterrows():\n",
    "        combined_embedding = row['combined_embeddings']  # Assuming combined_embeddings is a precomputed field\n",
    "        cosine_sim = cosine_similarity([user_embedding], [combined_embedding])[0][0]\n",
    "        cosine_similarities.append((row['id'], row['title'], cosine_sim))\n",
    "    return cosine_similarities\n",
    "\n",
    "# Function to find and rerank similar texts using combined WordNet and cosine similarity\n",
    "def find_and_rerank_similar_texts(user_query, df_id, vectorizer, top_n=5, alpha=0.5):\n",
    "    wordnet_similarities = []\n",
    "    for idx, row in df_id.iterrows():\n",
    "        document = row['title'] + \" \" + row['abstract']  # Combine title and abstract\n",
    "        sim_score = text_similarity(user_query, document)\n",
    "        wordnet_similarities.append((row['id'], row['title'], sim_score))\n",
    "    \n",
    "    cosine_similarities = compute_cosine_similarity(user_query, df_id, vectorizer)\n",
    "    \n",
    "    combined_similarities = []\n",
    "    for (id1, title1, wordnet_sim), (id2, title2, cosine_sim) in zip(wordnet_similarities, cosine_similarities):\n",
    "        assert id1 == id2  # Ensure that the IDs match\n",
    "        combined_sim = alpha * wordnet_sim + (1 - alpha) * cosine_sim\n",
    "        combined_similarities.append((id1, title1, combined_sim))\n",
    "    \n",
    "    # Sort by combined similarity in descending order\n",
    "    combined_similarities.sort(key=lambda x: x[2], reverse=True)\n",
    "    return combined_similarities[:top_n]\n",
    "\n",
    "# Function to recommend papers based on user input using combined similarities\n",
    "def recommend_articles(user_query, df_id, vectorizer, top_n=5, alpha=0.5):\n",
    "    # Find and rerank similar texts using combined similarities\n",
    "    similar_texts = find_and_rerank_similar_texts(user_query, df_id, vectorizer, top_n, alpha)\n",
    "    \n",
    "    recommended_articles = []\n",
    "    for id, title, score in similar_texts:\n",
    "        recommended_articles.append((id, title, score))\n",
    "    \n",
    "    return recommended_articles\n",
    "\n",
    "# Example usage\n",
    "user_queries = [\n",
    "    \"Bibliography on cyclostationarity\"\n",
    "]\n",
    "\n",
    "for user_query in user_queries:\n",
    "    print(f\"User Input Exact Title: '{user_query}':\")\n",
    "    \n",
    "    # Check for exact title match in df_id1\n",
    "    exact_match_id, exact_match_title = find_exact_title_match(user_query, df_id1)\n",
    "    \n",
    "    if exact_match_id is not None:\n",
    "        print(f\"ID: {exact_match_id}, Title: {exact_match_title}\")\n",
    "    else:\n",
    "        print(f\"No exact title match found in df_id1 for '{user_query}'\")\n",
    "    \n",
    "    # Proceed with recommendation if no exact match found\n",
    "    recommended_articles = recommend_articles(user_query, df_id, vectorizer, top_n=5, alpha=0.5)\n",
    "    for rank, (id, title, score) in enumerate(recommended_articles, 1):\n",
    "        print(f\"Rank {rank}: ID: {id}, Title: {title}, Combined Similarity Score: {score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipline 4: Jacord smilirty using the wordNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import wordnet as wn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import jaccard_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming nltk data is already downloaded in your environment\n",
    "\n",
    "# Function to find the ID and title based on an exact title match\n",
    "def find_exact_title_match(title_query, df_id1):\n",
    "    for idx, row in df_id1.iterrows():\n",
    "        if row['title'].strip().lower() == title_query.strip().lower():\n",
    "            return row['id'], row['title']\n",
    "    return None, None  # Return None if no exact match is found\n",
    "\n",
    "# Function to compute WordNet similarity between two words\n",
    "def wordnet_similarity(word1, word2):\n",
    "    synsets1 = wn.synsets(word1)\n",
    "    synsets2 = wn.synsets(word2)\n",
    "    if not synsets1 or not synsets2:  # If either word has no synsets\n",
    "        return 0\n",
    "    max_sim = max((syn1.path_similarity(syn2) or 0) for syn1 in synsets1 for syn2 in synsets2)\n",
    "    return max_sim\n",
    "\n",
    "# Function to compute similarity between two texts using WordNet\n",
    "def text_similarity(text1, text2):\n",
    "    words1 = text1.split()\n",
    "    words2 = text2.split()\n",
    "    if not words1 or not words2:  # If either text has no valid words\n",
    "        return 0\n",
    "    total_sim = 0\n",
    "    for word1 in words1:\n",
    "        word_sim = max(wordnet_similarity(word1, word2) for word2 in words2)\n",
    "        total_sim += word_sim\n",
    "    return total_sim / max(len(words1), len(words2))  # Normalize by the number of words\n",
    "\n",
    "# Function to compute Jaccard similarity\n",
    "def compute_jaccard_similarity(user_query, df_id, vectorizer):\n",
    "    user_embedding = vectorizer.transform([user_query]).toarray().squeeze()\n",
    "    jaccard_similarities = []\n",
    "    for idx, row in df_id.iterrows():\n",
    "        document_embedding = row['combined_embeddings']  # Assuming combined_embeddings is a precomputed field\n",
    "        jaccard_sim = jaccard_score(user_embedding, document_embedding, average='binary')\n",
    "        jaccard_similarities.append((row['id'], row['title'], jaccard_sim))\n",
    "    return jaccard_similarities\n",
    "\n",
    "# Function to find and rerank similar texts using combined WordNet and Jaccard similarity\n",
    "def find_and_rerank_similar_texts(user_query, df_id, vectorizer, top_n=5, alpha=0.5):\n",
    "    wordnet_similarities = []\n",
    "    for idx, row in df_id.iterrows():\n",
    "        document = row['title'] + \" \" + row['abstract']  # Combine title and abstract\n",
    "        sim_score = text_similarity(user_query, document)\n",
    "        wordnet_similarities.append((row['id'], row['title'], sim_score))\n",
    "    \n",
    "    jaccard_similarities = compute_jaccard_similarity(user_query, df_id, vectorizer)\n",
    "    \n",
    "    combined_similarities = []\n",
    "    for (id1, title1, wordnet_sim), (id2, title2, jaccard_sim) in zip(wordnet_similarities, jaccard_similarities):\n",
    "        assert id1 == id2  # Ensure that the IDs match\n",
    "        combined_sim = alpha * wordnet_sim + (1 - alpha) * jaccard_sim\n",
    "        combined_similarities.append((id1, title1, combined_sim))\n",
    "    \n",
    "    # Sort by combined similarity in descending order\n",
    "    combined_similarities.sort(key=lambda x: x[2], reverse=True)\n",
    "    return combined_similarities[:top_n]\n",
    "\n",
    "# Function to recommend papers based on user input using combined similarities\n",
    "def recommend_articles(user_query, df_id, vectorizer, top_n=5, alpha=0.5):\n",
    "    # Find and rerank similar texts using combined similarities\n",
    "    similar_texts = find_and_rerank_similar_texts(user_query, df_id, vectorizer, top_n, alpha)\n",
    "    \n",
    "    recommended_articles = []\n",
    "    for id, title, score in similar_texts:\n",
    "        recommended_articles.append((id, title, score))\n",
    "    \n",
    "    return recommended_articles\n",
    "\n",
    "# Example usage\n",
    "user_queries = [\n",
    "    \"Bibliography on cyclostationarity\"\n",
    "]\n",
    "\n",
    "for user_query in user_queries:\n",
    "    print(f\"User Input Exact Title: '{user_query}':\")\n",
    "    \n",
    "    # Check for exact title match in df_id1\n",
    "    exact_match_id, exact_match_title = find_exact_title_match(user_query, df_id1)\n",
    "    \n",
    "    if exact_match_id is not None:\n",
    "        print(f\"ID: {exact_match_id}, Title: {exact_match_title}\")\n",
    "    else:\n",
    "        print(f\"No exact title match found in df_id1 for '{user_query}'\")\n",
    "    \n",
    "    # Proceed with recommendation if no exact match found\n",
    "    recommended_articles = recommend_articles(user_query, df_id, vectorizer, top_n=5, alpha=0.5)\n",
    "    for rank, (id, title, score) in enumerate(recommended_articles, 1):\n",
    "        print(f\"Rank {rank}: ID: {id}, Title: {title}, Combined Similarity Score: {score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipline 5: SentiWordNet using the Cosine Smilirty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import sentiwordnet as swn\n",
    "from nltk.corpus import wordnet as wn\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Function to find the ID and title based on an exact title match\n",
    "def find_exact_title_match(title_query, df_id1):\n",
    "    for idx, row in df_id1.iterrows():\n",
    "        if row['title'].strip().lower() == title_query.strip().lower():\n",
    "            return row['id'], row['title']\n",
    "    return None, None  # Return None if no exact match is found\n",
    "\n",
    "# Function to compute SentiWordNet sentiment score for a word\n",
    "def sentiwordnet_score(word):\n",
    "    synsets = wn.synsets(word)\n",
    "    if not synsets:\n",
    "        return 0, 0, 0  # No sentiment score if no synsets are found\n",
    "\n",
    "    pos_score, neg_score, obj_score = 0, 0, 0\n",
    "    for synset in synsets:\n",
    "        senti_synset = swn.senti_synset(synset.name())\n",
    "        pos_score += senti_synset.pos_score()\n",
    "        neg_score += senti_synset.neg_score()\n",
    "        obj_score += senti_synset.obj_score()\n",
    "    return pos_score, neg_score, obj_score\n",
    "\n",
    "# Function to compute sentiment similarity between two words\n",
    "def sentiment_similarity(word1, word2):\n",
    "    pos1, neg1, obj1 = sentiwordnet_score(word1)\n",
    "    pos2, neg2, obj2 = sentiwordnet_score(word2)\n",
    "    # Similarity based on positive and negative sentiment scores\n",
    "    return (pos1 * pos2 + neg1 * neg2) / (np.sqrt((pos1 ** 2 + neg1 ** 2) * (pos2 ** 2 + neg2 ** 2)) + 1e-10)\n",
    "\n",
    "# Function to compute similarity between two texts using SentiWordNet\n",
    "def text_similarity(text1, text2):\n",
    "    words1 = text1.split()\n",
    "    words2 = text2.split()\n",
    "    if not words1 or not words2:  # If either text has no valid words\n",
    "        return 0\n",
    "    total_sim = 0\n",
    "    for word1 in words1:\n",
    "        word_sim = max(sentiment_similarity(word1, word2) for word2 in words2)\n",
    "        total_sim += word_sim\n",
    "    return total_sim / max(len(words1), len(words2))  # Normalize by the number of words\n",
    "\n",
    "# Function to compute Cosine similarity\n",
    "def compute_cosine_similarity(user_query, df_id, vectorizer):\n",
    "    user_embedding = vectorizer.transform([user_query]).toarray()\n",
    "    cosine_similarities = []\n",
    "    for idx, row in df_id.iterrows():\n",
    "        document_embedding = np.array(row['combined_embeddings']).reshape(1, -1)  # Assuming combined_embeddings is a precomputed field\n",
    "        cosine_sim = cosine_similarity(user_embedding, document_embedding)[0][0]\n",
    "        cosine_similarities.append((row['id'], row['title'], cosine_sim))\n",
    "    return cosine_similarities\n",
    "\n",
    "# Function to find and rerank similar texts using combined SentiWordNet and Cosine similarity\n",
    "def find_and_rerank_similar_texts(user_query, df_id, vectorizer, top_n=5, alpha=0.5):\n",
    "    sentiwordnet_similarities = []\n",
    "    for idx, row in df_id.iterrows():\n",
    "        document = row['title'] + \" \" + row['abstract']  # Combine title and abstract\n",
    "        sim_score = text_similarity(user_query, document)\n",
    "        sentiwordnet_similarities.append((row['id'], row['title'], sim_score))\n",
    "    \n",
    "    cosine_similarities = compute_cosine_similarity(user_query, df_id, vectorizer)\n",
    "    \n",
    "    combined_similarities = []\n",
    "    for (id1, title1, sentiwordnet_sim), (id2, title2, cosine_sim) in zip(sentiwordnet_similarities, cosine_similarities):\n",
    "        assert id1 == id2  # Ensure that the IDs match\n",
    "        combined_sim = alpha * sentiwordnet_sim + (1 - alpha) * cosine_sim\n",
    "        combined_similarities.append((id1, title1, combined_sim))\n",
    "    \n",
    "    # Sort by combined similarity in descending order\n",
    "    combined_similarities.sort(key=lambda x: x[2], reverse=True)\n",
    "    return combined_similarities[:top_n]\n",
    "\n",
    "# Function to recommend papers based on user input using combined similarities\n",
    "def recommend_articles(user_query, df_id, vectorizer, top_n=5, alpha=0.5):\n",
    "    # Find and rerank similar texts using combined similarities\n",
    "    similar_texts = find_and_rerank_similar_texts(user_query, df_id, vectorizer, top_n, alpha)\n",
    "    \n",
    "    recommended_articles = []\n",
    "    for id, title, score in similar_texts:\n",
    "        recommended_articles.append((id, title, score))\n",
    "    \n",
    "    return recommended_articles\n",
    "\n",
    "# Example usage\n",
    "user_queries = [\n",
    "    \"Bibliography on cyclostationarity\"\n",
    "]\n",
    "\n",
    "# Assuming 'vectorizer' is already defined and fitted\n",
    "vectorizer = TfidfVectorizer()  # Replace with your actual vectorizer\n",
    "\n",
    "for user_query in user_queries:\n",
    "    print(f\"User Input Exact Title: '{user_query}':\")\n",
    "    \n",
    "    # Check for exact title match in df_id1\n",
    "    exact_match_id, exact_match_title = find_exact_title_match(user_query, df_id1)\n",
    "    \n",
    "    if exact_match_id is not None:\n",
    "        print(f\"ID: {exact_match_id}, Title: {exact_match_title}\")\n",
    "    else:\n",
    "        print(f\"No exact title match found in df_id1 for '{user_query}'\")\n",
    "    \n",
    "    # Proceed with recommendation if no exact match found\n",
    "    recommended_articles = recommend_articles(user_query, df_id, vectorizer, top_n=5, alpha=0.5)\n",
    "    for rank, (id, title, score) in enumerate(recommended_articles, 1):\n",
    "        print(f\"Rank {rank}: ID: {id}, Title: {title}, Combined Similarity Score: {score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipline 6: SentiwordNet using the Jaccord_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import sentiwordnet as swn\n",
    "from nltk.corpus import wordnet as wn\n",
    "from sklearn.metrics import jaccard_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Function to find the ID and title based on an exact title match\n",
    "def find_exact_title_match(title_query, df_id1):\n",
    "    for idx, row in df_id1.iterrows():\n",
    "        if row['title'].strip().lower() == title_query.strip().lower():\n",
    "            return row['id'], row['title']\n",
    "    return None, None  # Return None if no exact match is found\n",
    "\n",
    "# Function to compute SentiWordNet sentiment score for a word\n",
    "def sentiwordnet_score(word):\n",
    "    synsets = wn.synsets(word)\n",
    "    if not synsets:\n",
    "        return 0, 0, 0  # No sentiment score if no synsets are found\n",
    "\n",
    "    pos_score, neg_score, obj_score = 0, 0, 0\n",
    "    for synset in synsets:\n",
    "        senti_synset = swn.senti_synset(synset.name())\n",
    "        pos_score += senti_synset.pos_score()\n",
    "        neg_score += senti_synset.neg_score()\n",
    "        obj_score += senti_synset.obj_score()\n",
    "    return pos_score, neg_score, obj_score\n",
    "\n",
    "# Function to compute sentiment similarity between two words\n",
    "def sentiment_similarity(word1, word2):\n",
    "    pos1, neg1, obj1 = sentiwordnet_score(word1)\n",
    "    pos2, neg2, obj2 = sentiwordnet_score(word2)\n",
    "    # Similarity based on positive and negative sentiment scores\n",
    "    return (pos1 * pos2 + neg1 * neg2) / (np.sqrt((pos1 ** 2 + neg1 ** 2) * (pos2 ** 2 + neg2 ** 2)) + 1e-10)\n",
    "\n",
    "# Function to compute similarity between two texts using SentiWordNet\n",
    "def text_similarity(text1, text2):\n",
    "    words1 = text1.split()\n",
    "    words2 = text2.split()\n",
    "    if not words1 or not words2:  # If either text has no valid words\n",
    "        return 0\n",
    "    total_sim = 0\n",
    "    for word1 in words1:\n",
    "        word_sim = max(sentiment_similarity(word1, word2) for word2 in words2)\n",
    "        total_sim += word_sim\n",
    "    return total_sim / max(len(words1), len(words2))  # Normalize by the number of words\n",
    "\n",
    "# Function to compute Jaccard similarity\n",
    "def compute_jaccard_similarity(user_query, df_id, vectorizer):\n",
    "    user_embedding = vectorizer.transform([user_query]).toarray().squeeze()\n",
    "    jaccard_similarities = []\n",
    "    for idx, row in df_id.iterrows():\n",
    "        document_embedding = row['combined_embeddings']  # Assuming combined_embeddings is a precomputed field\n",
    "        jaccard_sim = jaccard_score(user_embedding, document_embedding, average='binary')\n",
    "        jaccard_similarities.append((row['id'], row['title'], jaccard_sim))\n",
    "    return jaccard_similarities\n",
    "\n",
    "# Function to find and rerank similar texts using combined SentiWordNet and Jaccard similarity\n",
    "def find_and_rerank_similar_texts(user_query, df_id, vectorizer, top_n=5, alpha=0.5):\n",
    "    sentiwordnet_similarities = []\n",
    "    for idx, row in df_id.iterrows():\n",
    "        document = row['title'] + \" \" + row['abstract']  # Combine title and abstract\n",
    "        sim_score = text_similarity(user_query, document)\n",
    "        sentiwordnet_similarities.append((row['id'], row['title'], sim_score))\n",
    "    \n",
    "    jaccard_similarities = compute_jaccard_similarity(user_query, df_id, vectorizer)\n",
    "    \n",
    "    combined_similarities = []\n",
    "    for (id1, title1, sentiwordnet_sim), (id2, title2, jaccard_sim) in zip(sentiwordnet_similarities, jaccard_similarities):\n",
    "        assert id1 == id2  # Ensure that the IDs match\n",
    "        combined_sim = alpha * sentiwordnet_sim + (1 - alpha) * jaccard_sim\n",
    "        combined_similarities.append((id1, title1, combined_sim))\n",
    "    \n",
    "    # Sort by combined similarity in descending order\n",
    "    combined_similarities.sort(key=lambda x: x[2], reverse=True)\n",
    "    return combined_similarities[:top_n]\n",
    "\n",
    "# Function to recommend papers based on user input using combined similarities\n",
    "def recommend_articles(user_query, df_id, vectorizer, top_n=5, alpha=0.5):\n",
    "    # Find and rerank similar texts using combined similarities\n",
    "    similar_texts = find_and_rerank_similar_texts(user_query, df_id, vectorizer, top_n, alpha)\n",
    "    \n",
    "    recommended_articles = []\n",
    "    for id, title, score in similar_texts:\n",
    "        recommended_articles.append((id, title, score))\n",
    "    \n",
    "    return recommended_articles\n",
    "\n",
    "# Example usage\n",
    "user_queries = [\n",
    "    \"Bibliography on cyclostationarity\"\n",
    "]\n",
    "\n",
    "# Assuming 'vectorizer' is already defined and fitted\n",
    "vectorizer = TfidfVectorizer()  # Replace with your actual vectorizer\n",
    "\n",
    "for user_query in user_queries:\n",
    "    print(f\"User Input Exact Title: '{user_query}':\")\n",
    "    \n",
    "    # Check for exact title match in df_id1\n",
    "    exact_match_id, exact_match_title = find_exact_title_match(user_query, df_id1)\n",
    "    \n",
    "    if exact_match_id is not None:\n",
    "        print(f\"ID: {exact_match_id}, Title: {exact_match_title}\")\n",
    "    else:\n",
    "        print(f\"No exact title match found in df_id1 for '{user_query}'\")\n",
    "    \n",
    "    # Proceed with recommendation if no exact match found\n",
    "    recommended_articles = recommend_articles(user_query, df_id, vectorizer, top_n=5, alpha=0.5)\n",
    "    for rank, (id, title, score) in enumerate(recommended_articles, 1):\n",
    "        print(f\"Rank {rank}: ID: {id}, Title: {title}, Combined Similarity Score: {score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipline 7: LLM using the Cosine Smilirty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from scipy.spatial.distance import cosine\n",
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "import random\n",
    "\n",
    "# Load the SciBERT model and tokenizer\n",
    "model_name = \"allenai/scibert_scivocab_uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "# Function to get embeddings\n",
    "def get_embeddings(text):\n",
    "    inputs = tokenizer(text, return_tensors='pt', padding=True, truncation=True)\n",
    "    with torch.no_grad():\n",
    "        embeddings = model(**inputs).last_hidden_state.mean(dim=1)\n",
    "    return embeddings\n",
    "\n",
    "# Assuming df_id1 is your DataFrame with 'title' and 'abstract' columns\n",
    "\n",
    "# Combine title and abstract\n",
    "df_id1['combined_text'] = df_id1['title'] + ' ' + df_id1['abstract']\n",
    "\n",
    "# Get embeddings for combined text\n",
    "df_id1['combined_embeddings'] = df_id1['combined_text'].apply(lambda x: get_embeddings(x).squeeze().numpy())\n",
    "\n",
    "# Convert numpy arrays to lists\n",
    "df_id1['combined_embeddings'] = df_id1['combined_embeddings'].apply(lambda x: x.tolist())\n",
    "\n",
    "# Convert combined text to string for metadata\n",
    "df_id1['combined_str'] = df_id1['combined_text'].apply(lambda x: ' '.join(x.split()))\n",
    "\n",
    "# Connect to Chroma and create a collection\n",
    "client = chromadb.Client(Settings())\n",
    "combined_collection = client.create_collection(\"combined_embeddings\")\n",
    "\n",
    "# Add embeddings to the collection\n",
    "ids = df_id1[\"id\"].tolist()\n",
    "combined_embeddings = df_id1[\"combined_embeddings\"].tolist()\n",
    "combined_metadatas = df_id1[[\"combined_str\"]].to_dict(orient=\"records\")\n",
    "\n",
    "combined_collection.add(ids=ids, embeddings=combined_embeddings, metadatas=combined_metadatas)\n",
    "\n",
    "# Function to compute similarity\n",
    "def compute_similarity(embedding1, embedding2):\n",
    "    return 1 - cosine(embedding1, embedding2)\n",
    "\n",
    "# Function to find similar texts\n",
    "def find_similar_texts(user_input, top_n=5):\n",
    "    user_embedding = get_embeddings(user_input).squeeze().numpy().tolist()\n",
    "    \n",
    "    similarities = []\n",
    "    for idx, row in df_id1.iterrows():\n",
    "        sim = compute_similarity(user_embedding, row['combined_embeddings'])\n",
    "        similarities.append((row['id'], sim))\n",
    "    \n",
    "    # Sort by similarity and get top N results\n",
    "    similarities.sort(key=lambda x: x[1], reverse=True)\n",
    "    return similarities[:top_n]\n",
    "\n",
    "# Function for re-ranking the results\n",
    "def re_rank_results(similar_texts):\n",
    "    # Your re-ranking logic here (if any)\n",
    "    return similar_texts  # For simplicity, returning the same list\n",
    "\n",
    "# Updated function to find similar texts and re-rank them\n",
    "def find_and_rerank_similar_texts(user_input, top_n=5):\n",
    "    similar_texts = find_similar_texts(user_input, top_n)\n",
    "    re_ranked_texts = re_rank_results(similar_texts)\n",
    "    return re_ranked_texts\n",
    "\n",
    "# Function to recommend papers (example random recommendation)\n",
    "def recommend_papers(user_input, num_recommendations=5):\n",
    "    recommended_papers = random.sample(df_id1[\"id\"].tolist(), num_recommendations)\n",
    "    return recommended_papers\n",
    "\n",
    "# Function to calculate BERTScore for recommended papers\n",
    "def calculate_bertscore_for_recommendations(user_input, recommended_papers):\n",
    "    candidates = [user_input] * len(recommended_papers)\n",
    "    references = [df_id1[df_id1[\"id\"] == paper_id][\"combined_str\"].values[0] for paper_id in recommended_papers]\n",
    "    P, R, F1 = bert_score(candidates, references, lang=\"en\", verbose=True)\n",
    "    return {\n",
    "        \"precision\": P.mean().item(),\n",
    "        \"recall\": R.mean().item(),\n",
    "        \"f1_score\": F1.mean().item()\n",
    "    }\n",
    "\n",
    "# Function to find exact title match\n",
    "def find_exact_title_match(title_query, df_id1):\n",
    "    for idx, row in df_id1.iterrows():\n",
    "        if row['title'].strip().lower() == title_query.strip().lower():\n",
    "            return row['id'], row['title']\n",
    "    return None, None  # Return None if no exact match is found\n",
    "\n",
    "# Example usage\n",
    "user_input = \"recommendation system based on semantic analysis\"\n",
    "similar_texts = find_and_rerank_similar_texts(user_input)\n",
    "recommended_papers = recommend_papers(user_input)\n",
    "\n",
    "# Display the results for combined text\n",
    "print(\"Similar Combined Texts:\")\n",
    "for id, similarity in similar_texts:\n",
    "    combined_text = df_id1[df_id1[\"id\"] == id][\"combined_text\"].values[0]\n",
    "    print(f\"Combined Text: {combined_text}, Similarity: {similarity}\")\n",
    "\n",
    "# Display recommended papers\n",
    "print(\"Recommended Papers:\")\n",
    "for paper_id in recommended_papers:\n",
    "    combined_text = df_id1[df_id1[\"id\"] == paper_id][\"combined_text\"].values[0]\n",
    "    print(f\"Paper ID: {paper_id}, Combined Text: {combined_text}\")\n",
    "\n",
    "# Calculate BERTScore for recommended papers\n",
    "bert_metrics_recommended_papers = calculate_bertscore_for_recommendations(user_input, recommended_papers)\n",
    "\n",
    "# Display the BERTScore for recommended papers\n",
    "print(\"BERTScore Metrics for Recommended Papers:\")\n",
    "print(f\"Precision: {bert_metrics_recommended_papers['precision']:.2f}\")\n",
    "print(f\"Recall: {bert_metrics_recommended_papers['recall']:.2f}\")\n",
    "print(f\"F1 Score: {bert_metrics_recommended_papers['f1_score']:.2f}\")\n",
    "\n",
    "# Example usage of find_exact_title_match function\n",
    "title_query = \"Example Title 1\"\n",
    "matched_id, matched_title = find_exact_title_match(title_query, df_id1)\n",
    "print(f\"Exact match - ID: {matched_id}, Title: {matched_title}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from scipy.spatial.distance import cosine\n",
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "\n",
    "# Load the SciBERT model and tokenizer\n",
    "model_name = \"allenai/scibert_scivocab_uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "# Function to get embeddings\n",
    "def get_embeddings(text):\n",
    "    inputs = tokenizer(text, return_tensors='pt', padding=True, truncation=True)\n",
    "    with torch.no_grad():\n",
    "        embeddings = model(**inputs).last_hidden_state.mean(dim=1)\n",
    "    return embeddings\n",
    "\n",
    "# Assuming df is your DataFrame with 'title' and 'abstract' columns\n",
    "df = pd.DataFrame({\n",
    "    'title': [\"Example Title 1\", \"Example Title 2\"],\n",
    "    'abstract': [\"This is an example abstract 1.\", \"This is an example abstract 2.\"],\n",
    "    '_id': [1, 2]\n",
    "})\n",
    "\n",
    "# Get embeddings for titles and abstracts\n",
    "df_id1['title_embeddings'] = df_id1['title'].apply(lambda x: get_embeddings(x).squeeze().numpy())\n",
    "df_id1['abstract_embeddings'] = df_id1['abstract'].apply(lambda x: get_embeddings(x).squeeze().numpy())\n",
    "\n",
    "# Convert numpy arrays to lists\n",
    "df_id1['title_embeddings'] = df_id1['title_embeddings'].apply(lambda x: x.tolist())\n",
    "df_id1['abstract_embeddings'] = df_id1['abstract_embeddings'].apply(lambda x: x.tolist())\n",
    "\n",
    "# Convert lists in 'abstract' to strings for metadata\n",
    "df['abstract_str'] = df['abstract'].apply(lambda x: ' '.join(x.split()))\n",
    "\n",
    "# Connect to Chroma and create collections\n",
    "client = chromadb.Client(Settings())\n",
    "title_collection = client.create_collection(\"title_embeddings\")\n",
    "abstract_collection = client.create_collection(\"abstract_embeddings\")\n",
    "\n",
    "# Add embeddings to collections\n",
    "ids = df[\"_id\"].tolist()\n",
    "title_embeddings = df[\"title_embeddings\"].tolist()\n",
    "abstract_embeddings = df[\"abstract_embeddings\"].tolist()\n",
    "title_metadatas = df[[\"title\"]].to_dict(orient=\"records\")\n",
    "abstract_metadatas = df[[\"abstract_str\"]].to_dict(orient=\"records\")\n",
    "\n",
    "title_collection.add(ids=ids, embeddings=title_embeddings, metadatas=title_metadatas)\n",
    "abstract_collection.add(ids=ids, embeddings=abstract_embeddings, metadatas=abstract_metadatas)\n",
    "\n",
    "# Function to compute similarity\n",
    "def compute_similarity(embedding1, embedding2):\n",
    "    return 1 - cosine(embedding1, embedding2)\n",
    "\n",
    "# Function to find similar texts\n",
    "def find_similar_texts(user_input, embedding_column, top_n=5):\n",
    "    user_embedding = get_embeddings(user_input).squeeze().numpy().tolist()\n",
    "    \n",
    "    similarities = []\n",
    "    for idx, row in df.iterrows():\n",
    "        sim = compute_similarity(user_embedding, row[embedding_column])\n",
    "        similarities.append((row['_id'], sim))\n",
    "    \n",
    "    # Sort by similarity and get top N results\n",
    "    similarities.sort(key=lambda x: x[1], reverse=True)\n",
    "    return similarities[:top_n]\n",
    "\n",
    "# Function for re-ranking the results\n",
    "def re_rank_results(similar_texts):\n",
    "    # Your re-ranking logic here (if any)\n",
    "    return similar_texts  # For simplicity, returning the same list\n",
    "\n",
    "# Updated function to find similar texts and re-rank them\n",
    "def find_and_rerank_similar_texts(user_input, embedding_column, top_n=5):\n",
    "    similar_texts = find_similar_texts(user_input, embedding_column, top_n)\n",
    "    re_ranked_texts = re_rank_results(similar_texts)\n",
    "    return re_ranked_texts\n",
    "\n",
    "# Function to recommend papers (example random recommendation)\n",
    "def recommend_papers(user_input, num_recommendations=5):\n",
    "    recommended_papers = random.sample(df[\"_id\"].tolist(), num_recommendations)\n",
    "    return recommended_papers\n",
    "\n",
    "# Function to calculate BERTScore for recommended papers\n",
    "def calculate_bertscore_for_recommendations(user_input, recommended_papers):\n",
    "    candidates = [user_input] * len(recommended_papers)\n",
    "    references = [df[df[\"_id\"] == paper_id][\"abstract_str\"].values[0] for paper_id in recommended_papers]\n",
    "    P, R, F1 = bert_score(candidates, references, lang=\"en\", verbose=True)\n",
    "    return {\n",
    "        \"precision\": P.mean().item(),\n",
    "        \"recall\": R.mean().item(),\n",
    "        \"f1_score\": F1.mean().item()\n",
    "    }\n",
    "\n",
    "# Example usage\n",
    "user_input = \"recommendation system based on semantic analysis\"\n",
    "similar_titles = find_and_rerank_similar_texts(user_input, 'title_embeddings')\n",
    "similar_abstracts = find_and_rerank_similar_texts(user_input, 'abstract_embeddings')\n",
    "recommended_papers = recommend_papers(user_input)\n",
    "\n",
    "# Display the results for titles\n",
    "print(\"Similar Titles:\")\n",
    "for _id, similarity in similar_titles:\n",
    "    title = df[df[\"_id\"] == _id][\"title\"].values[0]\n",
    "    print(f\"Title: {title}, Similarity: {similarity}\")\n",
    "\n",
    "# Display the results for abstracts\n",
    "print(\"Similar Abstracts:\")\n",
    "for _id, similarity in similar_abstracts:\n",
    "    title = df[df[\"_id\"] == _id][\"title\"].values[0]\n",
    "    print(f\"Title: {title}, Similarity: {similarity}\")\n",
    "\n",
    "# Display recommended papers\n",
    "print(\"Recommended Papers:\")\n",
    "for paper_id in recommended_papers:\n",
    "    title = df[df[\"_id\"] == paper_id][\"title\"].values[0]\n",
    "    print(f\"Paper ID: {paper_id}, Title: {title}\")\n",
    "\n",
    "# Calculate BERTScore for recommended papers\n",
    "bert_metrics_recommended_papers = calculate_bertscore_for_recommendations(user_input, recommended_papers)\n",
    "\n",
    "# Display the BERTScore for recommended papers\n",
    "print(\"BERTScore Metrics for Recommended Papers:\")\n",
    "print(f\"Precision: {bert_metrics_recommended_papers['precision']:.2f}\")\n",
    "print(f\"Recall: {bert_metrics_recommended_papers['recall']:.2f}\")\n",
    "print(f\"F1 Score: {bert_metrics_recommended_papers['f1_score']:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User Input Exact Title: 'A new approach of 3D watermarking based on image segmentation':\n",
      "ID: 4ab3735c-80f1-472d-b953-fa0557fed28b, Title: A new approach of 3D watermarking based on image segmentation\n",
      "Rank 1: ID: 67a59884-926e-4d8f-b638-c5140b91dcf2, Title: ['paraphras', 'identif', 'lexicosyntact', 'graph', 'subsumpt'], Similarity Score: 0.5292\n",
      "Rank 2: ID: 505ea144-8353-456e-8adf-f0818f3bef0c, Title: ['teach', 'objectsfirst', 'introductori', 'comput', 'scienc'], Similarity Score: 0.4904\n",
      "Rank 3: ID: 536eddb5-b1ac-45dc-9dc7-2734970c84d2, Title: ['differ', 'quantis', 'nois', 'shape', 'method', 'predict', 'audio', 'code'], Similarity Score: 0.4603\n",
      "Rank 4: ID: 5ceab604-7649-4484-ac79-05bff7111aaf, Title: ['componentbas', 'approach', 'improv', 'modular', 'oscar'], Similarity Score: 0.4534\n",
      "Rank 5: ID: 6926c0c1-ef07-40ab-9992-ca2346b890c0, Title: ['branchandcut', 'approach', 'gener', 'multipleproduct', 'assemblysystem', 'design', 'problem'], Similarity Score: 0.4507\n"
     ]
    },
    {
     "ename": "SyntaxError",
     "evalue": "'[' was never closed (<string>, line 1)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[1;36m(most recent call last)\u001b[0m:\n",
      "\u001b[0m  File \u001b[0;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py:3460\u001b[0m in \u001b[0;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\u001b[0m\n",
      "\u001b[0m  Cell \u001b[0;32mIn[65], line 115\u001b[0m\n    precision, recall, f1_score = evaluate_recommendations(exact_match_id, recommendation_ids)\u001b[0m\n",
      "\u001b[1;36m  Cell \u001b[1;32mIn[65], line 50\u001b[1;36m in \u001b[1;35mevaluate_recommendations\u001b[1;36m\n\u001b[1;33m    user_references = eval(user_references) if isinstance(user_references, str) else user_references\u001b[1;36m\n",
      "\u001b[1;36m  File \u001b[1;32m<string>:1\u001b[1;36m\u001b[0m\n\u001b[1;33m    ['09cb2d7d-47d1-4a85-bfe5-faa8221e644b'\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m '[' was never closed\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Function to find the ID and title based on an exact title match\n",
    "def find_exact_title_match(title_query, df_id1):\n",
    "    for idx, row in df_id1.iterrows():\n",
    "        if row['title'].strip().lower() == title_query.strip().lower():\n",
    "            return row['id'], row['title']\n",
    "    return None, None  # Return None if no exact match is found\n",
    "\n",
    "# Function to find and rerank similar texts using combined embeddings\n",
    "def find_and_rerank_similar_texts(user_query, top_n=5):\n",
    "    user_embedding = vectorizer.transform([user_query]).toarray().squeeze()\n",
    "    \n",
    "    similarities = []\n",
    "    for idx, row in df_id.iterrows():\n",
    "        combined_embedding = row['combined_embeddings']\n",
    "        \n",
    "        # Compute cosine similarity between user embedding and combined embedding\n",
    "        combined_sim = cosine_similarity([user_embedding], [combined_embedding])[0][0]\n",
    "        \n",
    "        similarities.append((row['id'], row['title'], combined_sim))\n",
    "    \n",
    "    # Sort by combined similarity in descending order\n",
    "    similarities.sort(key=lambda x: x[2], reverse=True)\n",
    "    return similarities[:top_n]\n",
    "\n",
    "# Function to recommend papers based on user input using combined embeddings\n",
    "def recommend_articles(user_query, top_n=5):\n",
    "    # Find and rerank similar texts using combined embeddings\n",
    "    similar_texts = find_and_rerank_similar_texts(user_query, top_n)\n",
    "    \n",
    "    recommended_articles = []\n",
    "    for id, title, score in similar_texts:\n",
    "        recommended_articles.append((id, title, score))\n",
    "    \n",
    "    return recommended_articles\n",
    "\n",
    "# Function to evaluate recommendations based on citation relationship\n",
    "def evaluate_recommendations(user_id, recommendation_ids):\n",
    "    user_references = df_referce[df_referce['id'] == user_id]['references'].values\n",
    "    if len(user_references) > 0:\n",
    "        user_references = user_references[0]\n",
    "        if pd.isna(user_references):\n",
    "            user_references = []\n",
    "        elif isinstance(user_references, float):\n",
    "            user_references = []\n",
    "        else:\n",
    "            user_references = eval(user_references) if isinstance(user_references, str) else user_references\n",
    "    else:\n",
    "        user_references = []\n",
    "\n",
    "    evaluation_matrix = []\n",
    "    for rec_id in recommendation_ids:\n",
    "        rec_references = df_referce[df_referce['id'] == rec_id]['references'].values\n",
    "        if len(rec_references) > 0:\n",
    "            rec_references = rec_references[0]\n",
    "            if pd.isna(rec_references):\n",
    "                rec_references = []\n",
    "            elif isinstance(rec_references, float):\n",
    "                rec_references = []\n",
    "            else:\n",
    "                rec_references = eval(rec_references) if isinstance(rec_references, str) else rec_references\n",
    "        else:\n",
    "            rec_references = []\n",
    "\n",
    "        in_user_references = rec_id in user_references\n",
    "        user_id_in_rec_references = user_id in rec_references\n",
    "        \n",
    "        evaluation_matrix.append((rec_id, in_user_references, user_id_in_rec_references))\n",
    "    \n",
    "    # Create DataFrame for evaluation matrix\n",
    "    df_evaluation = pd.DataFrame(evaluation_matrix, columns=['Recommended_ID', 'In_User_References', 'User_ID_in_Rec_References'])\n",
    "    \n",
    "    # Calculate metrics\n",
    "    true_positives = sum(df_evaluation['In_User_References'] | df_evaluation['User_ID_in_Rec_References'])\n",
    "    false_positives = len(df_evaluation) - true_positives\n",
    "    total_relevant_items = len(set(user_references).union(set(recommendation_ids)))\n",
    "    false_negatives = total_relevant_items - true_positives\n",
    "\n",
    "    precision = true_positives / (true_positives + false_positives) if (true_positives + false_positives) > 0 else 0\n",
    "    recall = true_positives / (true_positives + false_negatives) if (true_positives + false_negatives) > 0 else 0\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "    return precision, recall, f1_score\n",
    "\n",
    "# Example usage\n",
    "user_queries = [\n",
    "    \"A new approach of 3D watermarking based on image segmentation\"\n",
    "]\n",
    "\n",
    "for user_query in user_queries:\n",
    "    print(f\"User Input Exact Title: '{user_query}':\")\n",
    "    \n",
    "    # Check for exact title match in df_id1\n",
    "    exact_match_id, exact_match_title = find_exact_title_match(user_query, df_id1)\n",
    "    \n",
    "    if exact_match_id is not None:\n",
    "        print(f\"ID: {exact_match_id}, Title: {exact_match_title}\")\n",
    "        # stored_variable = (exact_match_id, exact_match_title)  # Store in variable\n",
    "        # print(f\"Stored Variable: {stored_variable}\")\n",
    "    else:\n",
    "        print(f\"No exact title match found in df_id1 for '{user_query}'\")\n",
    "    \n",
    "    # Proceed with recommendation if no exact match found\n",
    "    recommended_articles = recommend_articles(user_query, top_n=5)\n",
    "    recommendation_ids = [id for id, title, score in recommended_articles]\n",
    "    \n",
    "    for rank, (id, title, score) in enumerate(recommended_articles, 1):\n",
    "        print(f\"Rank {rank}: ID: {id}, Title: {title}, Similarity Score: {score:.4f}\")\n",
    "\n",
    "    # Evaluate recommendations if there are recommended articles\n",
    "    if recommendation_ids:\n",
    "        precision, recall, f1_score = evaluate_recommendations(exact_match_id, recommendation_ids)\n",
    "        print(f\"Precision: {precision:.4f}\")\n",
    "        print(f\"Recall: {recall:.4f}\")\n",
    "        print(f\"F1 Score: {f1_score:.4f}\")\n",
    "    else:\n",
    "        print(\"No recommendations to evaluate.\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Function to clean and format references\n",
    "def format_references(references):\n",
    "    \"\"\"\n",
    "    Clean and format references data.\n",
    "    - Remove extra brackets at the start and end\n",
    "    - Strip extra whitespace\n",
    "    - Split by commas\n",
    "    \"\"\"\n",
    "    if isinstance(references, str):\n",
    "        # Remove extra brackets and whitespace\n",
    "        cleaned_references = re.sub(r'^\\[|\\]$', '', references).strip()\n",
    "        # Split by commas and remove any extra whitespace\n",
    "        reference_list = [ref.strip() for ref in cleaned_references.split(',') if ref.strip()]\n",
    "        return reference_list\n",
    "    elif isinstance(references, list):\n",
    "        # If references are already a list, ensure no unwanted brackets or whitespace\n",
    "        return [ref.strip() for ref in references if ref.strip()]\n",
    "    return []\n",
    "\n",
    "# Function to evaluate recommendations based on citation relationship\n",
    "def evaluate_recommendations(user_id, recommendation_ids):\n",
    "    user_references = df_referce[df_referce['id'] == user_id]['references'].values\n",
    "    if len(user_references) > 0:\n",
    "        user_references = user_references[0]\n",
    "        user_references = format_references(user_references)\n",
    "    else:\n",
    "        user_references = []\n",
    "\n",
    "    evaluation_matrix = []\n",
    "    for rec_id in recommendation_ids:\n",
    "        rec_references = df_referce[df_referce['id'] == rec_id]['references'].values\n",
    "        if len(rec_references) > 0:\n",
    "            rec_references = rec_references[0]\n",
    "            rec_references = format_references(rec_references)\n",
    "        else:\n",
    "            rec_references = []\n",
    "\n",
    "        in_user_references = rec_id in user_references\n",
    "        user_id_in_rec_references = user_id in rec_references\n",
    "        \n",
    "        evaluation_matrix.append((rec_id, in_user_references, user_id_in_rec_references))\n",
    "    \n",
    "    # Create DataFrame for evaluation matrix\n",
    "    df_evaluation = pd.DataFrame(evaluation_matrix, columns=['Recommended_ID', 'In_User_References', 'User_ID_in_Rec_References'])\n",
    "    \n",
    "    # Calculate metrics\n",
    "    true_positives = sum(df_evaluation['In_User_References'] | df_evaluation['User_ID_in_Rec_References'])\n",
    "    false_positives = len(df_evaluation) - true_positives\n",
    "    total_relevant_items = len(set(user_references).union(set(recommendation_ids)))\n",
    "    false_negatives = total_relevant_items - true_positives\n",
    "\n",
    "    precision = true_positives / (true_positives + false_positives) if (true_positives + false_positives) > 0 else 0\n",
    "    recall = true_positives / (true_positives + false_negatives) if (true_positives + false_negatives) > 0 else 0\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "    return precision, recall, f1_score\n",
    "\n",
    "# Example usage\n",
    "user_queries = [\n",
    "    \"A new approach of 3D watermarking based on image segmentation\"\n",
    "]\n",
    "\n",
    "for user_query in user_queries:\n",
    "    print(f\"User Input Exact Title: '{user_query}':\")\n",
    "    \n",
    "    # Check for exact title match in df_id1\n",
    "    exact_match_id, exact_match_title = find_exact_title_match(user_query, df_id1)\n",
    "    \n",
    "    if exact_match_id is not None:\n",
    "        print(f\"ID: {exact_match_id}, Title: {exact_match_title}\")\n",
    "        # stored_variable = (exact_match_id, exact_match_title)  # Store in variable\n",
    "        # print(f\"Stored Variable: {stored_variable}\")\n",
    "    else:\n",
    "        print(f\"No exact title match found in df_id1 for '{user_query}'\")\n",
    "    \n",
    "    # Proceed with recommendation if no exact match found\n",
    "    recommended_articles = recommend_articles(user_query, top_n=5)\n",
    "    recommendation_ids = [id for id, title, score in recommended_articles]\n",
    "    \n",
    "    for rank, (id, title, score) in enumerate(recommended_articles, 1):\n",
    "        print(f\"Rank {rank}: ID: {id}, Title: {title}, Similarity Score: {score:.4f}\")\n",
    "\n",
    "    # Evaluate recommendations if there are recommended articles\n",
    "    if recommendation_ids:\n",
    "        precision, recall, f1_score = evaluate_recommendations(exact_match_id, recommendation_ids)\n",
    "        print(f\"Precision: {precision:.4f}\")\n",
    "        print(f\"Recall: {recall:.4f}\")\n",
    "        print(f\"F1 Score: {f1_score:.4f}\")\n",
    "    else:\n",
    "        print(\"No recommendations to evaluate.\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# from scipy.spatial.distance import cosine\n",
    "# import chromadb\n",
    "# import numpy as np\n",
    "# from chromadb.config import Settings\n",
    "\n",
    "# # Load data\n",
    "\n",
    "# # Ensure the 'title' and 'abstract' columns contain strings\n",
    "# df_id['title'] = df_id['title'].astype(str)\n",
    "# df_id['abstract'] = df_id['abstract'].apply(lambda x: ' '.join(x) if isinstance(x, list) else str(x))\n",
    "\n",
    "# # Example additional metadata for re-ranking\n",
    "# df_id['citation_count'] = df_id['n_citation']  # Use actual citation counts\n",
    "\n",
    "# # Create TF-IDF vectorizer\n",
    "# vectorizer = TfidfVectorizer(max_features=768)  # Adjust the max_features based on your needs\n",
    "\n",
    "# # Fit and transform the title and abstract columns\n",
    "# df_id['title_embeddings'] = list(vectorizer.fit_transform(df_id['title']).toarray())\n",
    "# df_id['abstract_embeddings'] = list(vectorizer.fit_transform(df_id['abstract']).toarray())\n",
    "\n",
    "# # Convert lists in 'abstract' to strings for metadata\n",
    "# df_id['abstract_str'] = df_id['abstract']\n",
    "\n",
    "# # Ensure IDs are strings\n",
    "# df_id['_id'] = df_id['_id'].astype(str)\n",
    "\n",
    "# # Connect to Chroma and create collections\n",
    "# client = chromadb.Client(Settings())\n",
    "# title_collection = client.create_collection(\"title_embeddings\")\n",
    "# abstract_collection = client.create_collection(\"abstract_embeddings\")\n",
    "\n",
    "# # Add embeddings to collections\n",
    "# ids = df_id[\"_id\"].tolist()\n",
    "# title_embeddings = df_id[\"title_embeddings\"].tolist()\n",
    "# abstract_embeddings = df_id[\"abstract_embeddings\"].tolist()\n",
    "# title_metadatas = df_id[[\"title\"]].to_dict(orient=\"records\")\n",
    "# abstract_metadatas = df_id[[\"abstract_str\"]].to_dict(orient=\"records\")\n",
    "\n",
    "# title_collection.add(ids=ids, embeddings=title_embeddings, metadatas=title_metadatas)\n",
    "# abstract_collection.add(ids=ids, embeddings=abstract_embeddings, metadatas=abstract_metadatas)\n",
    "\n",
    "# # Function to compute similarity\n",
    "# def compute_similarity(embedding1, embedding2):\n",
    "#     return 1 - cosine(embedding1, embedding2)\n",
    "\n",
    "# # Function to find similar texts\n",
    "# def find_similar_texts(user_input, embedding_column, top_n=5):\n",
    "#     user_embedding = vectorizer.transform([user_input]).toarray().squeeze()\n",
    "    \n",
    "#     similarities = []\n",
    "#     for idx, row in df_id.iterrows():\n",
    "#         sim = compute_similarity(user_embedding, row[embedding_column])\n",
    "#         similarities.append((row['_id'], sim))\n",
    "    \n",
    "#     # Sort by similarity and get top N results\n",
    "#     similarities.sort(key=lambda x: x[1], reverse=True)\n",
    "#     return similarities[:top_n]\n",
    "\n",
    "# # Function for re-ranking the results\n",
    "# def re_rank_results(similar_texts):\n",
    "#     # Combine similarity score with citation count for re-ranking\n",
    "#     re_ranked = []\n",
    "#     for _id, similarity in similar_texts:\n",
    "#         citation_count = df_id[df_id[\"_id\"] == _id][\"citation_count\"].values[0]\n",
    "#         # Example: Weighted combination of similarity and citation count\n",
    "#         re_ranked_score = 0.8 * similarity + 0.2 * (citation_count / 100)  # Normalize citation_count to 0-1 range\n",
    "#         re_ranked.append((_id, re_ranked_score))\n",
    "    \n",
    "#     # Sort by re-ranked score\n",
    "#     re_ranked.sort(key=lambda x: x[1], reverse=True)\n",
    "#     return re_ranked\n",
    "\n",
    "# # Updated function to find similar texts and re-rank them\n",
    "# def find_and_rerank_similar_texts(user_input, embedding_column, top_n=5):\n",
    "#     similar_texts = find_similar_texts(user_input, embedding_column, top_n)\n",
    "#     re_ranked_texts = re_rank_results(similar_texts)\n",
    "#     return re_ranked_texts\n",
    "\n",
    "# # Function to recommend papers (example random recommendation)\n",
    "# def recommend_papers(user_input, num_recommendations=5):\n",
    "#     recommended_papers = df_id[\"_id\"].tolist()[:num_recommendations]  # Simplified for demonstration\n",
    "#     return recommended_papers\n",
    "\n",
    "# # Example usage\n",
    "# user_input = \"recommendation system based on semantic analysis\"\n",
    "# similar_titles = find_and_rerank_similar_texts(user_input, 'title_embeddings')\n",
    "# similar_abstracts = find_and_rerank_similar_texts(user_input, 'abstract_embeddings')\n",
    "# recommended_papers = recommend_papers(user_input)\n",
    "\n",
    "# # Display the results for titles\n",
    "# print(\"Similar Titles:\")\n",
    "# for _id, similarity in similar_titles:\n",
    "#     title = df_id[df_id[\"_id\"] == _id][\"title\"].values[0]\n",
    "#     print(f\"Title: {title}, Similarity: {similarity}\")\n",
    "\n",
    "# # Display the results for abstracts\n",
    "# print(\"Similar Abstracts:\")\n",
    "# for _id, similarity in similar_abstracts:\n",
    "#     title = df_id[df_id[\"_id\"] == _id][\"title\"].values[0]\n",
    "#     print(f\"Title: {title}, Similarity: {similarity}\")\n",
    "\n",
    "# # Display recommended papers\n",
    "# print(\"Recommended Papers:\")\n",
    "# for paper_id in recommended_papers:\n",
    "#     title = df_id[df_id[\"_id\"] == paper_id][\"title\"].values[0]\n",
    "#     print(f\"Paper ID: {paper_id}, Title: {title}\")\n",
    "\n",
    "# # Function to recommend articles based on user query\n",
    "# def recommend_articles(user_query, top_n=5):\n",
    "#     # Transform the user query into a TF-IDF embedding\n",
    "#     query_embedding = vectorizer.transform([user_query]).toarray().squeeze()\n",
    "\n",
    "#     # Retrieve similar documents from the collection\n",
    "#     docs = title_collection.query(embeddings=[query_embedding], n_results=top_n)\n",
    "\n",
    "#     recommended_articles = []\n",
    "#     for doc in docs['documents']:\n",
    "#         if doc is None or 'metadatas' not in doc or 'embeddings' not in doc:\n",
    "#             continue  # Skip if document metadata or embeddings are missing\n",
    "\n",
    "#         metadata = doc['metadatas'][0]\n",
    "#         embedding = np.array(doc['embeddings'][0])\n",
    "\n",
    "#         # Ensure embedding is a 1D array\n",
    "#         if len(embedding.shape) == 1:\n",
    "#             similarity_score = 1 - cosine(query_embedding, embedding)\n",
    "#             recommended_articles.append((metadata['title'], similarity_score))\n",
    "\n",
    "#     # Sort the recommended articles by similarity score\n",
    "#     recommended_articles.sort(key=lambda x: x[1], reverse=True)\n",
    "#     return recommended_articles[:top_n]\n",
    "\n",
    "# # Example usage\n",
    "# user_query = \"Deep learning for natural language processing\"\n",
    "# recommended_articles = recommend_articles(user_query, top_n=5)\n",
    "\n",
    "# # Display the recommended articles\n",
    "# print(\"Recommended Articles:\")\n",
    "# for title, score in recommended_articles:\n",
    "#     print(f\"Title: {title}, Similarity Score: {score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# from chromadb.config import Settings\n",
    "# from chromadb import Client\n",
    "# import chromadb\n",
    "\n",
    "\n",
    "# #\n",
    "# # Combine 'clean_title' and 'clean_abstract' for embedding\n",
    "# df_id['combined_text'] = df_id['clean_title'].fillna('') + ' ' + df_id['clean_abstract'].fillna('')\n",
    "\n",
    "# # Initialize the TF-IDF vectorizer\n",
    "# vectorizer = TfidfVectorizer(max_features=5000)\n",
    "# X = vectorizer.fit_transform(df_id['combined_text'])\n",
    "\n",
    "# # Initialize the ChromaDB client\n",
    "# client = chromadb.Client()\n",
    "\n",
    "# # Create or connect to a Chroma collection\n",
    "# collection_name = \"research_papers2\"\n",
    "# if collection_name not in client.list_collections():\n",
    "#     client.create_collection(name=collection_name)\n",
    "# collection = client.get_collection(name=collection_name)\n",
    "\n",
    "# # Store the embeddings in the Chroma vector database\n",
    "# for idx, row in df_id.iterrows():\n",
    "#         vector = X[idx].toarray().flatten().tolist()\n",
    "#         doc_id = str(row['_id'])  # Ensure the ID is a string\n",
    "#         title_str = ' '.join(row['title']) if isinstance(row['title'], list) else str(row['title'])\n",
    "#         abstract_str = ' '.join(row['abstract']) if isinstance(row['abstract'], list) else str(row['abstract'])\n",
    "#         collection.add(ids=[doc_id], embeddings=[vector], metadatas=[{\n",
    "#         \"title\": title_str,\n",
    "#         \"abstract\": abstract_str\n",
    "#     }])\n",
    "\n",
    "# print(\"Embeddings successfully stored in the Chroma vector database.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# from sklearn.metrics.pairwise import cosine_similarity\n",
    "# from chromadb import Client\n",
    "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# # Assuming df_id, vectorizer, and collection are already defined from your previous code\n",
    "\n",
    "# # Function to recommend top articles based on a user query\n",
    "# def recommend_articles(user_query, top_n=5):\n",
    "#     # Vectorize the user query using the existing vectorizer\n",
    "#     user_query_vector = vectorizer.transform([user_query]).toarray().flatten()\n",
    "\n",
    "#     # Initialize a list to store document embeddings and metadata\n",
    "#     documents = []\n",
    "\n",
    "#     # Iterate over documents in the collection\n",
    "#     for idx in range(len(df_id)):\n",
    "#         doc_id = df_id.iloc[idx]['_id']\n",
    "#         doc = collection.get([str(doc_id)])\n",
    "        \n",
    "#         # Debug print to inspect document details\n",
    "#         print(f\"Processing document ID: {doc_id}\")\n",
    "#         print(doc)\n",
    "        \n",
    "#         if not doc['ids']:\n",
    "#             continue  # Skip if document ID is not found\n",
    "\n",
    "#         if not doc['metadatas'] or not doc['embeddings']:\n",
    "#             continue  # Skip if metadata or embeddings are not found\n",
    "        \n",
    "#         metadata = doc['metadatas'][0]\n",
    "#         embedding = doc['embeddings'][0]\n",
    "\n",
    "#         # Convert embedding to numpy array if necessary\n",
    "#         if isinstance(embedding, str):\n",
    "#             embedding = np.fromstring(embedding.strip('[]'), dtype=float, sep=',')\n",
    "        \n",
    "#         embedding = np.array(embedding)\n",
    "\n",
    "#         # Ensure embedding is a 1D array\n",
    "#         if len(embedding.shape) == 1:\n",
    "#             embedding = np.expand_dims(embedding, axis=0)\n",
    "        \n",
    "#         # Calculate cosine similarity between the user query vector and the stored vector\n",
    "#         similarity = cosine_similarity([user_query_vector], embedding)[0][0]\n",
    "#         documents.append((metadata, similarity))\n",
    "\n",
    "#     # Rerank the results based on similarity\n",
    "#     documents.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "#     # Recommend the top N articles\n",
    "#     top_articles = documents[:top_n]\n",
    "#     for rank, (article, similarity) in enumerate(top_articles, 1):\n",
    "#         print(f\"Rank {rank}:\")\n",
    "#         print(f\"Title: {article['title']}\")\n",
    "#         print(f\"Abstract: {article['abstract']}\")\n",
    "#         print(f\"Similarity: {similarity:.4f}\")\n",
    "#         print()\n",
    "\n",
    "# # Example usage\n",
    "# user_query = \"Deep learning for natural language processing\"\n",
    "# recommend_articles(user_query, top_n=5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from gensim.models import Word2Vec\n",
    "# from nltk.tokenize import word_tokenize\n",
    "\n",
    "# # Train Word2Vec model\n",
    "# model = Word2Vec(df_id['lemmatized_title'], vector_size=100, window=5, min_count=1, workers=4)\n",
    "# model1 = Word2Vec(df_id['lemmatized_abstract'], vector_size=100, window=5, min_count=1, workers=10)\n",
    "\n",
    "# # Function to get the vector representation of a sentence\n",
    "# def get_sentence_vector(tokens):\n",
    "#     vector_sum = sum(model.wv[token] for token in tokens if token in model.wv)\n",
    "#     return vector_sum / len(tokens)\n",
    "\n",
    "#     vector_sum1 = sum(model1.wv[token] for token in tokens if token in model1.wv)\n",
    "#     return vector_sum1 / len(tokens)\n",
    "\n",
    "# # Apply Word Embedding to lemmatized titles\n",
    "# df_id['word_embedding_title'] = df_id['lemmatized_title'].apply(get_sentence_vector)\n",
    "# df_id['word_embedding_abstract'] = df_id['lemmatized_abstract'].apply(get_sentence_vector)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_id['word_embedding_abstract']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_id['word_embedding_title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_id.to_csv(\"chunck100k.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df =df_id.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# from transformers import AutoTokenizer, AutoModel\n",
    "# import torch\n",
    "# from scipy.spatial.distance import cosine\n",
    "# import chromadb\n",
    "# from chromadb.config import Settings\n",
    "# from bert_score import score as bert_score\n",
    "# import random\n",
    "\n",
    "# # Load the dataset\n",
    "# # data = {\n",
    "# #     \"_id\": [\"65a756c9a99c69a267b682b1\", \"65a756c9a99c69a267b682b2\", \"65a756c9a99c69a267b682b3\", \"65a756c9a99c69a267b682b4\", \"65a756c9a99c69a267b682b5\"],\n",
    "# #     \"title\": [\n",
    "# #         \"whither expert social affordances and cultural knowledge bases question answer systems\",\n",
    "# #         \"solving the imprecise weight coefficients knapsack problem\",\n",
    "# #         \"combination of general antithetic transformations and methods for reducing the variance in the content\",\n",
    "# #         \"clustering worstcase execution times for componentbased systems classical techniques\",\n",
    "# #         \"reverse engineering goal models from legacy code\"\n",
    "# #     ],\n",
    "# #     \"abstract\": [\n",
    "# #         ['commun', 'base', 'question', 'answer', 'system'],\n",
    "# #         ['paper', 'investig', 'solv', 'imprecis', 'weight'],\n",
    "# #         ['sever', 'method', 'reduc', 'varianc', 'content'],\n",
    "# #         ['componenbas', 'system', 'classic', 'techniqu'],\n",
    "# #         ['revers', 'engin', 'process', 'aim', 'reconstruct']\n",
    "# #     ],\n",
    "# # }\n",
    "\n",
    "\n",
    "# Load the SciBERT model and tokenizer\n",
    "model_name = \"allenai/scibert_scivocab_uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "# Function to get embeddings\n",
    "def get_embeddings(text):\n",
    "    inputs = tokenizer(text, return_tensors='pt', padding=True, truncation=True)\n",
    "    with torch.no_grad():\n",
    "        embeddings = model(**inputs).last_hidden_state.mean(dim=1)\n",
    "    return embeddings\n",
    "\n",
    "# Get embeddings for titles and abstracts\n",
    "df['title_embeddings'] = df['title'].apply(lambda x: get_embeddings(x).squeeze().numpy())\n",
    "df['abstract_embeddings'] = df['abstract'].apply(lambda x: get_embeddings(' '.join(x)).squeeze().numpy())\n",
    "\n",
    "# Convert numpy arrays to lists\n",
    "df['title_embeddings'] = df['title_embeddings'].apply(lambda x: x.tolist())\n",
    "df['abstract_embeddings'] = df['abstract_embeddings'].apply(lambda x: x.tolist())\n",
    "\n",
    "# Convert lists in 'abstract' to strings for metadata\n",
    "df['abstract_str'] = df['abstract'].apply(lambda x: ' '.join(x))\n",
    "\n",
    "# Connect to Chroma and create collections\n",
    "client = chromadb.Client(Settings())\n",
    "title_collection = client.create_collection(\"title_embeddings\")\n",
    "abstract_collection = client.create_collection(\"abstract_embeddings\")\n",
    "\n",
    "# Add embeddings to collections\n",
    "ids = df[\"_id\"].tolist()\n",
    "title_embeddings = df[\"title_embeddings\"].tolist()\n",
    "abstract_embeddings = df[\"abstract_embeddings\"].tolist()\n",
    "title_metadatas = df[[\"title\"]].to_dict(orient=\"records\")\n",
    "abstract_metadatas = df[[\"abstract_str\"]].to_dict(orient=\"records\")\n",
    "\n",
    "title_collection.add(ids=ids, embeddings=title_embeddings, metadatas=title_metadatas)\n",
    "abstract_collection.add(ids=ids, embeddings=abstract_embeddings, metadatas=abstract_metadatas)\n",
    "\n",
    "# Function to compute similarity\n",
    "def compute_similarity(embedding1, embedding2):\n",
    "    return 1 - cosine(embedding1, embedding2)\n",
    "\n",
    "# Function to find similar texts\n",
    "def find_similar_texts(user_input, embedding_column, top_n=5):\n",
    "    user_embedding = get_embeddings(user_input).squeeze().numpy().tolist()\n",
    "    \n",
    "    similarities = []\n",
    "    for idx, row in df.iterrows():\n",
    "        sim = compute_similarity(user_embedding, row[embedding_column])\n",
    "        similarities.append((row['_id'], sim))\n",
    "    \n",
    "    # Sort by similarity and get top N results\n",
    "    similarities.sort(key=lambda x: x[1], reverse=True)\n",
    "    return similarities[:top_n]\n",
    "\n",
    "# Function for re-ranking the results\n",
    "def re_rank_results(similar_texts):\n",
    "    # Your re-ranking logic here\n",
    "    return similar_texts  # For simplicity, returning the same list\n",
    "\n",
    "# Updated function to find similar texts and re-rank them\n",
    "def find_and_rerank_similar_texts(user_input, embedding_column, top_n=5):\n",
    "    similar_texts = find_similar_texts(user_input, embedding_column, top_n)\n",
    "    re_ranked_texts = re_rank_results(similar_texts)\n",
    "    return re_ranked_texts\n",
    "\n",
    "# Function to recommend papers (example random recommendation)\n",
    "def recommend_papers(user_input, num_recommendations=5):\n",
    "    recommended_papers = random.sample(df[\"_id\"].tolist(), num_recommendations)\n",
    "    return recommended_papers\n",
    "\n",
    "# Function to calculate BERTScore for recommended papers\n",
    "def calculate_bertscore_for_recommendations(user_input, recommended_papers):\n",
    "    candidates = [user_input] * len(recommended_papers)\n",
    "    references = [df[df[\"_id\"] == paper_id][\"abstract_str\"].values[0] for paper_id in recommended_papers]\n",
    "    P, R, F1 = bert_score(candidates, references, lang=\"en\", verbose=True)\n",
    "    return {\n",
    "        \"precision\": P.mean().item(),\n",
    "        \"recall\": R.mean().item(),\n",
    "        \"f1_score\": F1.mean().item()\n",
    "    }\n",
    "\n",
    "# Example usage\n",
    "user_input = \"recommendation system based on semantic analysis\"\n",
    "similar_titles = find_and_rerank_similar_texts(user_input, 'title_embeddings')\n",
    "similar_abstracts = find_and_rerank_similar_texts(user_input, 'abstract_embeddings')\n",
    "recommended_papers = recommend_papers(user_input)\n",
    "\n",
    "# Display the results for titles\n",
    "print(\"Similar Titles:\")\n",
    "for _id, similarity in similar_titles:\n",
    "    title = df[df[\"_id\"] == _id][\"title\"].values[0]\n",
    "    print(f\"Title: {title}, Similarity: {similarity}\")\n",
    "\n",
    "# Display the results for abstracts\n",
    "print(\"Similar Abstracts:\")\n",
    "for _id, similarity in similar_abstracts:\n",
    "    title = df[df[\"_id\"] == _id][\"title\"].values[0]\n",
    "    print(f\"Title: {title}, Similarity: {similarity}\")\n",
    "\n",
    "# Display recommended papers\n",
    "print(\"Recommended Papers:\")\n",
    "for paper_id in recommended_papers:\n",
    "    title = df[df[\"_id\"] == paper_id][\"title\"].values[0]\n",
    "    print(f\"Paper ID: {paper_id}, Title: {title}\")\n",
    "\n",
    "# Calculate BERTScore for recommended papers\n",
    "bert_metrics_recommended_papers = calculate_bertscore_for_recommendations(user_input, recommended_papers)\n",
    "\n",
    "# Display the BERTScore for recommended papers\n",
    "print(\"BERTScore Metrics for Recommended Papers:\")\n",
    "print(f\"Precision: {bert_metrics_recommended_papers['precision']:.2f}\")\n",
    "print(f\"Recall: {bert_metrics_recommended_papers['recall']:.2f}\")\n",
    "print(f\"F1 Score: {bert_metrics_recommended_papers['f1_score']:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# from transformers import AutoTokenizer, AutoModel\n",
    "# import torch\n",
    "# from scipy.spatial.distance import cosine\n",
    "# import chromadb\n",
    "# from chromadb.config import Settings\n",
    "# from bert_score import score as bert_score\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # # Load the dataset\n",
    "# # data = {\n",
    "# #     \"_id\": [\"65a756c9a99c69a267b682b1\", \"65a756c9a99c69a267b682b2\", \"65a756c9a99c69a267b682b3\", \"65a756c9a99c69a267b682b4\", \"65a756c9a99c69a267b682b5\"],\n",
    "# #     \"title\": [\n",
    "# #         \"whither expert social affordances and cultural knowledge bases question answer systems\",\n",
    "# #         \"solving the imprecise weight coefficients knapsack problem\",\n",
    "# #         \"combination of general antithetic transformations and methods for reducing the variance in the content\",\n",
    "# #         \"clustering worstcase execution times for componentbased systems classical techniques\",\n",
    "# #         \"reverse engineering goal models from legacy code\"\n",
    "# #     ],\n",
    "# #     \"abstract\": [\n",
    "# #         ['commun', 'base', 'question', 'answer', 'system'],\n",
    "# #         ['paper', 'investig', 'solv', 'imprecis', 'weight'],\n",
    "# #         ['sever', 'method', 'reduc', 'varianc', 'content'],\n",
    "# #         ['componenbas', 'system', 'classic', 'techniqu'],\n",
    "# #         ['revers', 'engin', 'process', 'aim', 'reconstruct']\n",
    "# #     ],\n",
    "# # }\n",
    "\n",
    "# # df = pd.DataFrame(data)\n",
    "# df=pd.read_csv('chunck1.csv')\n",
    "# # Load the SciBERT model and tokenizer\n",
    "# model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "# model = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "# # Function to get embeddings\n",
    "# def get_embeddings(text):\n",
    "#     inputs = tokenizer(text, return_tensors='pt', padding=True, truncation=True)\n",
    "#     with torch.no_grad():\n",
    "#         embeddings = model(**inputs).last_hidden_state.mean(dim=1)\n",
    "#     return embeddings\n",
    "\n",
    "# # Get embeddings for titles and abstracts\n",
    "# df['title_embeddings'] = df['title'].apply(lambda x: get_embeddings(x).squeeze().numpy())\n",
    "# df['abstract_embeddings'] = df['abstract'].apply(lambda x: get_embeddings(' '.join(x)).squeeze().numpy())\n",
    "\n",
    "# # Convert numpy arrays to lists\n",
    "# df['title_embeddings'] = df['title_embeddings'].apply(lambda x: x.tolist())\n",
    "# df['abstract_embeddings'] = df['abstract_embeddings'].apply(lambda x: x.tolist())\n",
    "\n",
    "# # Convert lists in 'abstract' to strings for metadata\n",
    "# df['abstract_str'] = df['abstract'].apply(lambda x: ' '.join(x))\n",
    "\n",
    "# # Ensure IDs are strings\n",
    "# df['_id'] = df['_id'].astype(str)\n",
    "\n",
    "# # Connect to Chroma and create collections\n",
    "# client = chromadb.Client(Settings())\n",
    "# title_collection = client.create_collection(\"title_embeddings\")\n",
    "# abstract_collection = client.create_collection(\"abstract_embeddings\")\n",
    "\n",
    "# # Add embeddings to collections\n",
    "# ids = df[\"_id\"].tolist()\n",
    "# title_embeddings = df[\"title_embeddings\"].tolist()\n",
    "# abstract_embeddings = df[\"abstract_embeddings\"].tolist()\n",
    "# title_metadatas = df[[\"title\"]].to_dict(orient=\"records\")\n",
    "# abstract_metadatas = df[[\"abstract_str\"]].to_dict(orient=\"records\")\n",
    "\n",
    "# title_collection.add(ids=ids, embeddings=title_embeddings, metadatas=title_metadatas)\n",
    "# abstract_collection.add(ids=ids, embeddings=abstract_embeddings, metadatas=abstract_metadatas)\n",
    "\n",
    "# # Function to compute similarity\n",
    "# def compute_similarity(embedding1, embedding2):\n",
    "#     return 1 - cosine(embedding1, embedding2)\n",
    "\n",
    "# # Function to find similar texts\n",
    "# def find_similar_texts(user_input, embedding_column, top_n=5):\n",
    "#     user_embedding = get_embeddings(user_input).squeeze().numpy().tolist()\n",
    "    \n",
    "#     similarities = []\n",
    "#     for idx, row in df.iterrows():\n",
    "#         sim = compute_similarity(user_embedding, row[embedding_column])\n",
    "#         similarities.append((row['_id'], sim))\n",
    "    \n",
    "#     # Sort by similarity and get top N results\n",
    "#     similarities.sort(key=lambda x: x[1], reverse=True)\n",
    "#     return similarities[:top_n]\n",
    "\n",
    "# # Function for re-ranking the results\n",
    "# def re_rank_results(similar_texts):\n",
    "#     # Your re-ranking logic here\n",
    "#     return similar_texts  # For simplicity, returning the same list\n",
    "\n",
    "# # Updated function to find similar texts and re-rank them\n",
    "# def find_and_rerank_similar_texts(user_input, embedding_column, top_n=5):\n",
    "#     similar_texts = find_similar_texts(user_input, embedding_column, top_n)\n",
    "#     re_ranked_texts = re_rank_results(similar_texts)\n",
    "#     return re_ranked_texts\n",
    "\n",
    "# # Function to recommend papers (example random recommendation)\n",
    "# def recommend_papers(user_input, num_recommendations=5):\n",
    "#     recommended_papers = df[\"_id\"].tolist()[:num_recommendations]  # Simplified for demonstration\n",
    "#     return recommended_papers\n",
    "\n",
    "# # Function to calculate BERTScore for recommended papers\n",
    "# def calculate_bertscore_for_recommendations(user_input, recommended_papers):\n",
    "#     candidates = [user_input] * len(recommended_papers)\n",
    "#     references = [df[df[\"_id\"] == paper_id][\"abstract_str\"].values[0] for paper_id in recommended_papers]\n",
    "#     P, R, F1 = bert_score(candidates, references, lang=\"en\", verbose=True)\n",
    "#     return {\n",
    "#         \"precision\": P.mean().item(),\n",
    "#         \"recall\": R.mean().item(),\n",
    "#         \"f1_score\": F1.mean().item()\n",
    "#     }\n",
    "\n",
    "# # Example usage\n",
    "# user_input = \"recommendation system based on semantic analysis\"\n",
    "# similar_titles = find_and_rerank_similar_texts(user_input, 'title_embeddings')\n",
    "# similar_abstracts = find_and_rerank_similar_texts(user_input, 'abstract_embeddings')\n",
    "# recommended_papers = recommend_papers(user_input)\n",
    "\n",
    "# # Display the results for titles\n",
    "# print(\"Similar Titles:\")\n",
    "# for _id, similarity in similar_titles:\n",
    "#     title = df[df[\"_id\"] == _id][\"title\"].values[0]\n",
    "#     print(f\"Title: {title}, Similarity: {similarity}\")\n",
    "\n",
    "# # Display the results for abstracts\n",
    "# print(\"Similar Abstracts:\")\n",
    "# for _id, similarity in similar_abstracts:\n",
    "#     title = df[df[\"_id\"] == _id][\"title\"].values[0]\n",
    "#     print(f\"Title: {title}, Similarity: {similarity}\")\n",
    "\n",
    "# # Display recommended papers\n",
    "# print(\"Recommended Papers:\")\n",
    "# for paper_id in recommended_papers:\n",
    "#     title = df[df[\"_id\"] == paper_id][\"title\"].values[0]\n",
    "#     print(f\"Paper ID: {paper_id}, Title: {title}\")\n",
    "\n",
    "# # Calculate BERTScore for recommended papers\n",
    "# bert_metrics_recommended_papers = calculate_bertscore_for_recommendations(user_input, recommended_papers)\n",
    "\n",
    "# # Display the BERTScore for recommended papers\n",
    "# print(\"BERTScore Metrics for Recommended Papers:\")\n",
    "# print(f\"Precision: {bert_metrics_recommended_papers['precision']:.2f}\")\n",
    "# print(f\"Recall: {bert_metrics_recommended_papers['recall']:.2f}\")\n",
    "# print(f\"F1 Score: {bert_metrics_recommended_papers['f1_score']:.2f}\")\n",
    "\n",
    "# # Plotting BERTScore output and performance metrics\n",
    "# labels = ['Precision', 'Recall', 'F1 Score']\n",
    "# scores = [bert_metrics_recommended_papers['precision'], bert_metrics_recommended_papers['recall'], bert_metrics_recommended_papers['f1_score']]\n",
    "\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.bar(labels, scores, color=['blue', 'orange', 'green'])\n",
    "# plt.title('BERTScore Output and Performance Metrics')\n",
    "# plt.xlabel('Metrics')\n",
    "# plt.ylabel('Score')\n",
    "# plt.ylim(0, 1)  # Set y-axis limit from 0 to 1\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
